{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mestrado em Modelagem Matematica da Informacao\n",
    "----------------------------------------------\n",
    "Disciplina: Modelagem e Mineracao de Dados\n",
    "------------------------------------------\n",
    "\n",
    "Master Program - Mathematical Modeling of Information\n",
    "-----------------------------------------------------\n",
    "Course: Data Mining and Modeling\n",
    "--------------------------------\n",
    "\n",
    "Professor: Renato Rocha Souza\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic: Twitter Analysis and Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information on the Python Packages used:  \n",
    "https://github.com/bear/python-twitter (before was http://code.google.com/p/python-twitter/)  \n",
    "https://dev.twitter.com/docs  \n",
    "http://networkx.lanl.gov/  \n",
    "http://docs.python.org/library/re.html  \n",
    "http://nltk.org/  \n",
    "http://docs.python.org/library/xmlrpclib.html  \n",
    "http://docs.python.org/library/webbrowser.html  \n",
    "http://docs.python.org/library/codecs.html  \n",
    "http://matplotlib.sourceforge.net/  \n",
    "http://numpy.scipy.org/  \n",
    "http://docs.python.org/library/itertools.html  \n",
    "http://docs.python.org/library/sys.html  \n",
    "http://docs.python.org/library/json.html  \n",
    "http://docs.python.org/library/os  \n",
    "https://pypi.python.org/pypi/basemap/1.0.7  \n",
    "http://matplotlib.org/basemap/  \n",
    "http://matplotlib.org/basemap/users/installing.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import twitter\n",
    "import nltk\n",
    "import re\n",
    "import networkx as nx\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import webbrowser\n",
    "import codecs\n",
    "from itertools import cycle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import Image, HTML, IFrame, FileLink, FileLinks #needed to render in notebook\n",
    "from IPython.core.display import display\n",
    "import pydot  #Install http://www.graphviz.org/ & https://pypi.python.org/pypi/pydot2/1.0.32 pydot --> pip install pydot2\n",
    "\n",
    "%matplotlib inline\n",
    "# Set default figure size for this notebook\n",
    "plt.rcParams['figure.figsize'] = (16.0, 12.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying the path to the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "templates = \"/home/rsouza/Dropbox/Renato/ModMinDados/Git/templates/\"\n",
    "outputs = \"/home/rsouza/Dropbox/Renato/ModMinDados/outputs/\"\n",
    "\n",
    "dotfile = \"graph_retweet.dot\"\n",
    "pngfile = \"graph_retweet.png\"\n",
    "protofile = \"graph_retweet.html\"\n",
    "tweetsfile = \"Tweets_dump.txt\"\n",
    "template_proto = 'template_protoviz.html'\n",
    "\n",
    "pathdotfile = os.path.join(outputs,dotfile)\n",
    "pathpngfile = os.path.join(outputs,pngfile)\n",
    "pathprotofile = os.path.join(outputs,protofile)\n",
    "pathtweetsfile = os.path.join(outputs,tweetsfile)\n",
    "pathtemplate = os.path.join(templates,template_proto)\n",
    "\n",
    "stoplist_en = nltk.corpus.stopwords.words('english')\n",
    "stoplist_pt = nltk.corpus.stopwords.words('portuguese')\n",
    "ignorewords = stoplist_en + stoplist_pt + ['',' ','-','rt']\n",
    "\n",
    "twitter_query = u'ENEM'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Twitter API Keys  \n",
    "Please generate yours...  \n",
    "Go to http://twitter.com/apps/new to create an app and get these items  \n",
    "See https://dev.twitter.com/docs/auth/oauth for more information on Twitter's OAuth implementation  \n",
    "https://dev.twitter.com/rest/reference/get/account/verify_credentials  \n",
    "https://dev.twitter.com/docs/auth/oauth  \n",
    "https://dev.twitter.com/apps/new  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('twitter_tokens.txt', 'r') as twitter_tokens:\n",
    "    tokens = twitter_tokens.read().split(',')\n",
    "consumer_key = tokens[0].strip()\n",
    "consumer_secret = tokens[1].strip()\n",
    "access_token = tokens[2].strip()\n",
    "access_token_secret = tokens[3].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acessing Twitter (with or without authentication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#api = twitter.Api() # Accessing with no authentication\n",
    "api = twitter.Api(consumer_key, consumer_secret, access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print api.VerifyCredentials()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lexical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent (random) public messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "msgpublicas = api.GetStreamSample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    tweet = msgpublicas.next()\n",
    "    if tweet.has_key('text'):\n",
    "        print(u'{}\\n'.format(tweet['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweet Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "while True:\n",
    "    tweet = msgpublicas.next()\n",
    "    if tweet.has_key('user'):\n",
    "        break\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Image(url='http://mike.teczno.com/img/raffi-krikorian-map-of-a-tweet.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent messages from an user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "msguser = api.GetUserTimeline(tweet['user']['id'])\n",
    "print([s.text for s in msguser])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent messages from the authenticated user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "msguser = api.GetUserTimeline('rrsouza')\n",
    "#msguser = api.GetUserTimeline('29959702')\n",
    "print([s.text for s in msguser])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hometimeline = api.GetHomeTimeline()\n",
    "print([u.GetText() for u in hometimeline])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "search = api.GetSearch(twitter_query)\n",
    "print([s.text for s in search])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After authentication, more options are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "userfollow = api.GetFriends()\n",
    "print([u.name for u in userfollow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(text) / len(set(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for a term in tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def search_for_term(termo, pages, results):\n",
    "    '''Search and return tweets on a subject (5 pages of 100 results each)\n",
    "    Save results in a file defined in \"pathtweetsfile\" '''\n",
    "    search_results = []\n",
    "    tweets = []\n",
    "    tweets_txt = []\n",
    "    tweets_words = []\n",
    "    names = []\n",
    "    last = api.GetSearch(term=termo, count=1)\n",
    "    search_results.append(last)\n",
    "    list_ids = []\n",
    "    list_ids.append(last[0].GetId())\n",
    "    for i in range(pages):\n",
    "        id_last = last[0].GetId()\n",
    "        new_tweets = api.GetSearch(term=termo, count=results, max_id=min(list_ids))\n",
    "        for i in range(len(new_tweets)):\n",
    "            list_ids.append(new_tweets[i].GetId())\n",
    "        search_results.append(new_tweets)\n",
    "    for i in range(len(search_results)):\n",
    "        for j in range(len(search_results[i])):\n",
    "            tweets.append(search_results[i][j])\n",
    "    tweets_txt += [tweet.text.split(u' ') for tweet in tweets]\n",
    "    for i in range(len(tweets)):\n",
    "        tweets_words += [word.lower().strip(u':@&$!?') for word in tweets_txt[i]]\n",
    "    for i in range(len(tweets)): \n",
    "        names += [word.strip(u':@&$!?') for word in tweets_txt[i] if word.istitle() and len(word) > 2]\n",
    "    out = file(pathtweetsfile,'w')\n",
    "    for tweet in tweets_txt: \n",
    "        out.write(u'\\n{}'.format(tweet))\n",
    "    return tweets, tweets_txt, tweets_words, names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our customized function that retrieves 5 x 100 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets, tweets_txt, tweets_words, names = search_for_term(twitter_query,5,10)\n",
    "    \n",
    "print('Word count: {}'.format(len(tweets_words)))\n",
    "print('Repertoire: {}'.format(len(set(tweets_words))))\n",
    "print('Lexical diversity: {}'.format(lexical_diversity(tweets_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_dist = nltk.FreqDist(tweets_words)\n",
    "freq_dist.plot(40)\n",
    "freq_dist.plot(40, cumulative = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('10 most frequent words')\n",
    "print(freq_dist.keys()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('10 less frequent words')\n",
    "print(freq_dist.keys()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Sorted list of words')\n",
    "print(sorted(set(tweets_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before, without stopwords. See variable \"ignorewords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_tweets_words = [word for word in tweets_words if word not in ignorewords]\n",
    "    \n",
    "freq_new = nltk.FreqDist(new_tweets_words)    \n",
    "freq_new.plot(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_new.plot(50, cumulative = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('10 most frequent words')\n",
    "print(freq_new.keys()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('10 less frequent words')\n",
    "print(freq_new.keys()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Sorted list of words')\n",
    "print(sorted(set(new_tweets_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting specific words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(new_tweets_words.count(u'prova'))\n",
    "print(freq_new[u'gabarito']) #same as before\n",
    "print(freq_new.freq(u'cola')) #relative to the others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminating small words or words with specific sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigger_tweets_words = [word for word in new_tweets_words if len(word) > 2]\n",
    "#mediumsized_tweets_words = [word for word in new_tweets_words if len(word) > 2 and len(word) < 9]\n",
    "freq_bigger = nltk.FreqDist(bigger_tweets_words)    \n",
    "freq_bigger.plot(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "citacoes = [word for word in tweets_words if '@' in word]\n",
    "#citacoes = [word for word in tweets_words if word.startswith('@')]\n",
    "freq_citacoes = nltk.FreqDist(citacoes)\n",
    "freq_citacoes.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_citacoes.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hashtag Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtags = [word for word in tweets_words if word.startswith('#')]\n",
    "freq_hashtags = nltk.FreqDist(hashtags)\n",
    "freq_hashtags.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_hashtags.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of Frequent words  \n",
    "Can be used with any of the previous lists'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frequent_words = [word.lower() for word in new_tweets_words if tweets_words.count(word) > 5]\n",
    "freq_dist2 = nltk.FreqDist(frequent_words)\n",
    "freq_dist2.plot(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_size_words = nltk.FreqDist([len(w) for w in new_tweets_words])\n",
    "freq_size_words.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_size_words.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigramas_tweets = nltk.bigrams(new_tweets_words)\n",
    "freqbig = nltk.FreqDist(bigramas_tweets)\n",
    "freqbig.plot(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names (capitalized words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_names = nltk.FreqDist(names)\n",
    "freq_names.plot(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "badwords =   ['abandoned','abused','accused','addicted','afraid','aggravated',\n",
    "              'aggressive','alone','angry','anguish','annoyed','anxious','apprehensive',\n",
    "              'argumentative','artificial','ashamed','assaulted','at a loss','at risk',\n",
    "              'atrocious','attacked','avoided','awful','awkward','bad','badgered','baffled',\n",
    "              'banned','barren','beat','beaten down','belittled','berated','betrayed',\n",
    "              'bitched at','bitter','bizzare','blacklisted','blackmailed','blamed','bleak',\n",
    "              'blown away','blur','bored','boring','bossed-around','bothered','bothersome',\n",
    "              'bounded','boxed-in','broken','bruised','brushed-off','bugged','bullied',\n",
    "              'bummed','bummed out','burdened','burdensome','burned','burned-out',\n",
    "              'caged in','careless','chaotic','chased','cheated','cheated on','chicken',\n",
    "              'claustrophobic','clingy','closed','clueless','clumsy','coaxed',\n",
    "              'codependent','coerced','cold','cold-hearted','combative','commanded',\n",
    "              'compared','competitive','compulsive','conceited','concerned',\n",
    "              'condescended to','confined','conflicted','confronted','confused',\n",
    "              'conned','consumed','contemplative','contempt','contentious','controlled',\n",
    "              'convicted','cornered','corralled','cowardly','crabby','cramped','cranky',\n",
    "              'crap','crappy','crazy','creeped out','creepy','critical','criticized',\n",
    "              'cross','crowded','cruddy','crummy','crushed','cut-down','cut-off','cynical',\n",
    "              'damaged','damned','dangerous','dark','dazed','dead','deceived','deep',\n",
    "              'defamed','defeated','defective','defenseless','defensive','defiant',\n",
    "              'deficient','deflated','degraded','dehumanized','dejected','delicate',\n",
    "              'deluded','demanding','demeaned','demented','demoralized','demotivated',\n",
    "              'dependent','depleted','depraved','depressed','deprived','deserted',\n",
    "              'deserving of pain/punishment','desolate','despair','despairing',\n",
    "              'desperate','despicable','despised','destroyed','destructive',\n",
    "              'detached','detest','detestable','detested','devalued','devastated',\n",
    "              'deviant','devoid','diagnosed','dictated to','different','difficult',\n",
    "              'directionless','dirty','disabled','disagreeable','disappointed',\n",
    "              'disappointing','disapproved of','disbelieved','discardable','discarded',\n",
    "              'disconnected','discontent','discouraged','discriminated','disdain',\n",
    "              'disdainful','disempowered','disenchanted','disgraced','disgruntled',\n",
    "              'disgust','disgusted','disheartened','dishonest','dishonorable',\n",
    "              'disillusioned','dislike','disliked','dismal','dismayed','disorganized',\n",
    "              'disoriented','disowned','displeased','disposable','disregarded',\n",
    "              'disrespected','dissatisfied','distant','distracted','distraught',\n",
    "              'distressed','disturbed','dizzy','dominated','doomed','double-crossed',\n",
    "              'doubted','doubtful','down','down and out','down in the dumps',\n",
    "              'downhearted','downtrodden','drained','dramatic','dread','dreadful',\n",
    "              'dreary','dropped','drunk','dry','dumb','dumped','dumped on','duped',\n",
    "              'edgy','egocentric','egotistic','egotistical','elusive','emancipated',\n",
    "              'emasculated','embarrassed','emotional','emotionless','emotionally bankrupt',\n",
    "              'empty','encumbered','endangered','enraged','enslaved','entangled','evaded',\n",
    "              'evasive','evicted','excessive','excluded','exhausted','exploited','exposed',\n",
    "              'fail','failful','fake','false','fear','fearful','fed up','flawed','forced',\n",
    "              'forgetful','forgettable','forgotten','fragile','freaked out','frightened',\n",
    "              'frigid','frustrated','furious','gloomy','glum','gothic','grey','grief','grim',\n",
    "              'gross','grossed-out','grotesque','grouchy','grounded','grumpy','guilt-tripped',\n",
    "              'guilty','harassed','hard','hard-hearted','harmed','hassled','hate','hateful',\n",
    "              'hatred','haunted','heartbroken','heartless','heavy-hearted','helpless',\n",
    "              'hesitant','hideous','hindered','hopeless','horrible','horrified','horror',\n",
    "              'hostile','hot-tempered','humiliated','hung up','hung over','hurried','hurt',\n",
    "              'hysterical','idiot','idiotic','ignorant','ignored','ill','ill-tempered',\n",
    "              'imbalanced','imposed-upon','impotent','imprisoned','impulsive','in the dumps',\n",
    "              'in the way','inactive','inadequate','incapable','incommunicative','incompetent',\n",
    "              'incompatible','incomplete','incorrect','indecisive','indifferent',\n",
    "              'indoctrinated','inebriated','ineffective','inefficient','inferior',\n",
    "              'infuriated','inhibited','inhumane','injured','injusticed','insane',\n",
    "              'insecure','insignificant','insincere','insufficient','insulted',\n",
    "              'intense','interrogated','interrupted','intimidated','intoxicated',\n",
    "              'invalidated','invisible','irrational','irritable','irritated',\n",
    "              'isolated','jaded','jealous','jerked around','joyless','judged',\n",
    "              'kept apart','kept away','kept in','kept out','kept quiet','labeled',\n",
    "              'laughable','laughed at','lazy','leaned on','lectured to','left out',\n",
    "              'let down','lied about','lied to','limited','little','lonely','lonesome',\n",
    "              'longing','lost','lousy','loveless','low','mad','made fun of','man handled',\n",
    "              'manipulated','masochistic','messed with','messed up','messy','miffed',\n",
    "              'miserable','misled','mistaken','mistreated','mistrusted','misunderstood',\n",
    "              'mixed-up','mocked','molested','moody','nagged','needy','negative',\n",
    "              'nervous','neurotic','nonconforming','numb','nuts','nutty','objectified',\n",
    "              'obligated','obsessed','obsessive','obstructed','odd','offended',\n",
    "              'on display','opposed','oppressed','out of place','out of touch',\n",
    "              'over-controlled','over-protected','overwhelmed','pain','panic','paranoid',\n",
    "              'passive','pathetic','pessimistic','petrified','phony','picked on','pissed',\n",
    "              'pissed off','plain','played with','pooped','poor','powerless','pre-judged',\n",
    "              'preached to','preoccupied','predjudiced','pressured','prosecuted',\n",
    "              'provoked','psychopathic','psychotic','pulled apart','pulled back',\n",
    "              'punished','pushed','pushed away','put down','puzzled','quarrelsome',\n",
    "              'queer','questioned','quiet','rage','raped','rattled','regret','rejected',\n",
    "              'resented','resentful','responsible','retarded','revengeful','ridiculed',\n",
    "              'ridiculous','robbed','rotten','sad','sadistic','sarcastic','scared',\n",
    "              'scarred','screwed','screwed over','screwed up','self-centered','self-conscious',\n",
    "              'self-destructive','self-hatred','selfish','sensitive','shouted at','shy',\n",
    "              'singled-out','slow','small','smothered','snapped at','spiteful','stereotyped',\n",
    "              'strange','stressed','stretched','stuck','stupid','submissive','suffering',\n",
    "              'suffocated','suicidal','superficial','suppressed','suspicious','worse','worst'\n",
    "              ,'bankrupcy','jobs','shit','socialism','#sob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "goodwords =  ['Abundant','Accomplished','Achieving','Active','Admirable','Adorable',\n",
    "              'Adventurous','Admired','Affluent','Agreeable','Alert','Aligned','Alive',\n",
    "              'Amazing','Appealing','Appreciate','Artistic','Astounding','Astute',\n",
    "              'Attentive','Attractive','Auspicious','Authentic','Awake','Aware','Awesome',\n",
    "              'Beaming','Beautiful','Better','Best','Blessed','Bliss','Bold','Bright','Brilliant',\n",
    "              'Brisk','Buoyant','Calm','Capable','Centered','Certain','Charming',\n",
    "              'Cheerful','Clear','Clever','Competent','Complete','Confident','Connected',\n",
    "              'Conscious','Considerate','Convenient','Courageous','Creative','Daring',\n",
    "              'Dazzling','Delicious','Delightful','Desirable','Determined','Diligent',\n",
    "              'Discerning','Discover','Dynamic','Eager','Easy','Efficient','Effortless',\n",
    "              'Elegant','Eloquent','Energetic','Endless','Enhancing','Engaging','Enormous'\n",
    "              ,'Enterprising','Enthusiastic','Enticing','Excellent','Exceptional','Exciting'\n",
    "              ,'Experienced','Exquisite','Fabulous','Fair','Far-Sighted','Fascinating',\n",
    "              'Fine','Flattering','Flourishing','Fortunate','Free','Friendly','Fulfilled',\n",
    "              'Fun','Generous','Genuine','Gifted','Glorious','Glowing','Good','Good-Looking',\n",
    "              'Gorgeous','Graceful','Gracious','Grand','Great','Handsome','Happy','Hardy',\n",
    "              'Harmonious','Healed','Healthy','Helpful','Honest','Humorous','Ideal',\n",
    "              'Imaginative','Impressive','Industrious','Ingenious','Innovative','Inspired',\n",
    "              'Intelligent','Interested','Interesting','Intuitive','Inventive','Invincible',\n",
    "              'Inviting','Irresistible','Joyous','Judicious','Keen','Kind','Knowing','Leader',\n",
    "              'Limitless','Lively','Loving','Lucky','Luminous','Magical','Magnificent',\n",
    "              'Marvellous','Masterful','Mighty','Miraculous','Motivated','Natural','Neat',\n",
    "              'Nice','Nurturing','Noble','Optimistic','Outstanding','Passionate','Peaceful',\n",
    "              'Perfect','Persevering','Persistent','Playful','Pleasing','Plentiful','Positive',\n",
    "              'Powerful','Precious','Prepared','Productive','Profound','Prompt','Prosperous',\n",
    "              'Proud','Qualified','Quick','Radiant','Reasonable','Refined','Refreshing',\n",
    "              'Relaxing','Reliable','Remarkable','Resolute','Resourceful','Respected',\n",
    "              'Rewarding','Robust','Safe','Satisfied','Secure','Seductive','Self-Reliant',\n",
    "              'Sensational','Sensible','Sensitive','Serene','Sharing','Skilful','Smart',\n",
    "              'Smashing','Smooth','Sparkling','Spiritual','Splendid','Strong','Stunning',\n",
    "              'Successful','Superb','Swift','Talented','Tenacious','Terrific','Thankful',\n",
    "              'Thrilling','Thriving','Timely','Trusting','Truthful','Ultimate','Unique',\n",
    "              'Valiant','Valuable','Versatile','Vibrant','Victorious','Vigorous','Vivacious',\n",
    "              'Vivid','Warm','Wealthy','Well','Whole','Wise','Wonderful','Worthy','Young',\n",
    "              'Youthful','Zeal','Zest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def percentage(count, total):\n",
    "    return 100 * count / float(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sentiment_analysis(texto, goodwords, badwords):\n",
    "    '''\n",
    "    Not a sophisticated one, but the main idea is present.\n",
    "    Please read: http://alias-i.com/lingpipe/demos/tutorial/sentiment/read-me.html\n",
    "    '''\n",
    "    goodness = 0\n",
    "    badness = 0    \n",
    "    for word in goodwords:\n",
    "        goodness += percentage(texto.count(word.lower()), len(texto))\n",
    "    for word in badwords:\n",
    "        badness += percentage(texto.count(word.lower()), len(texto))\n",
    "    if badness:\n",
    "        ratio = goodness/float(badness)\n",
    "    print(u'Grau de negatividade: {}'.format(badness))\n",
    "    print(u'Grau de positividade: {}'.format(goodness))\n",
    "    if badness:\n",
    "        print(u'Razão: {}'.format(ratio))\n",
    "    return goodness, badness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment_analysis(tweets_words, goodwords, badwords);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geographic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pypi.python.org/pypi/basemap/1.0.7  \n",
    "http://matplotlib.org/basemap/  \n",
    "http://matplotlib.org/basemap/users/installing.html  \n",
    "http://nbviewer.ipython.org/github/ehmatthes/intro_programming/blob/master/notebooks/visualization_earthquakes.ipynb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#http://matplotlib.org/basemap/api/basemap_api.html\n",
    "from mpl_toolkits.basemap import Basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "geo_points = 0\n",
    "lats, lons = [], []\n",
    "users = []\n",
    "while geo_points < 20:\n",
    "    tweet = msgpublicas.next()\n",
    "    if tweet.has_key('coordinates') and tweet['coordinates'] != None:\n",
    "        coords = tweet['coordinates']['coordinates']\n",
    "        user = tweet['user']['id']\n",
    "        print(u'Usuário {} nas coordenadas {}'.format(user, [coords[1],coords[0]]))\n",
    "        lons.append(float(coords[0]))\n",
    "        lats.append(float(coords[1]))\n",
    "        users.append(user)\n",
    "        geo_points +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map = Basemap(projection='robin', resolution = 'l', area_thresh = 1000.0, lat_0=0, lon_0=-130)\n",
    "\n",
    "map.drawcoastlines()\n",
    "map.drawcountries()\n",
    "map.fillcontinents(color = '#FFFFCC') #http://www.w3schools.com/tags/ref_colorpicker.asp\n",
    "map.drawmapboundary()\n",
    "map.drawmeridians(np.arange(0, 360, 30))\n",
    "map.drawparallels(np.arange(-90, 90, 30))\n",
    "\n",
    "x,y = map(lons, lats)\n",
    "map.plot(x, y, 'ro', markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map = Basemap(projection='merc', lat_0 = -22, lon_0 = -56.5,resolution = 'h', area_thresh = 0.1, \n",
    "              llcrnrlon=-83.0, llcrnrlat=-57.0, urcrnrlon=-30.0, urcrnrlat=13.0)\n",
    " \n",
    "map.drawcoastlines()\n",
    "map.drawcountries()\n",
    "map.fillcontinents(color = 'coral')\n",
    "map.drawmapboundary()\n",
    "\n",
    "x,y = map(lons, lats)\n",
    "map.plot(x, y, 'bo', markersize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom em uma coordenada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gmap(lat,lon,zoom=10):\n",
    "    # Google Maps URL template for an iframe\n",
    "    google_maps_url = \"http://maps.google.com/maps?q={0}+{1}&ie=UTF8&t=h&z={2}&{0},{1}&output=embed\".format(lat,lon,zoom)\n",
    "    display(IFrame(google_maps_url, '800px', '600px'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gmap(lats[0],lons[0],4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_rt_origins(tweet):\n",
    "    ''' Regex adapted from \n",
    "    http://stackoverflow.com/questions/655903/python-regular-expression-for-retweets'''\n",
    "    rt_patterns = re.compile(r\"(RT|via)((?:\\b\\W*@\\w+)+)\", re.IGNORECASE)\n",
    "    rt_origins = []\n",
    "    try:\n",
    "        rt_origins += [mention.strip() for mention in rt_patterns.findall(tweet)[0][1].split()]\n",
    "    except IndexError, e:\n",
    "        pass\n",
    "    return [rto.strip(\"@\") for rto in rt_origins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_graph_retweets(tweets):\n",
    "    g = nx.DiGraph()\n",
    "    for tweet in tweets:\n",
    "        rt_origins = get_rt_origins(tweet.text)\n",
    "        if not rt_origins:\n",
    "            continue\n",
    "        for rt_origin in rt_origins:\n",
    "            g.add_edge(rt_origin, tweet.user.screen_name, {'tweet_id': tweet.id})\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g_rt = create_graph_retweets(tweets)\n",
    "print(\"Number of nodes is: {}\\n\".format(g_rt.number_of_nodes()))\n",
    "print(\"Number of edges is: {}\\n\".format(g_rt.number_of_edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_dic = sorted(g_rt.degree().items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic = nx.degree(g_rt)\n",
    "plt.plot(sorted(dic.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_dotfile(g):\n",
    "    try:\n",
    "        nx.drawing.write_dot(g, pathdotfile)\n",
    "        print >> sys.stderr, 'Graph exported for file: {}'.format(pathdotfile)\n",
    "    except (ImportError, UnicodeEncodeError): \n",
    "        # Este bloco serve para usuarios de windows, que certamente terao problemas\n",
    "        # com o metodo nx.drawing.write_dot. Tambem serve para os casos em que temos\n",
    "        # problemas com o unicode\n",
    "        dot = [u'\"{}\" -> \"{}\" [tweet_id={}]'.format(n1, n2, g[n1][n2]['tweet_id']) for (n1, n2) in g.edges()]\n",
    "        f = codecs.open(pathdotfile, 'w', encoding='utf-8')\n",
    "        f.write('''strict digraph {{}}'''.format(';\\n'.join(dot), ))\n",
    "        f.close()\n",
    "        print >> sys.stderr, 'Graph exported for file: {}'.format(pathdotfile)\n",
    "        return f.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_dotfile(g_rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving a dotfile\n",
    "\n",
    "Obs: To generate a png graph from the dotfile, type in the Unix Prompt: \n",
    "'circo -Tpng -Gcharset=latin1 -Ograph_retweet graph_retweet.dot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Chamando um programa externo ao Ipython com o operador !\n",
    "!dot -Tpng /home/rsouza/Dropbox/Renato/ModMinDados/outputs/graph_retweet.dot -o /home/rsouza/Dropbox/Renato/ModMinDados/outputs/graph_retweet.png\n",
    "Image(pathpngfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.draw_networkx_labels(g_rt,pos=nx.spring_layout(g_rt),font_size=9)\n",
    "nx.draw(g_rt)\n",
    "#nx.draw_random(g_rt)\n",
    "#nx.draw_circular(g_rt)\n",
    "#nx.draw_spectral(g_rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving a HTML file that uses javascript for visualizing the graph (needs a template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_protovis_file(g):\n",
    "    '''A visualization alternative is \"protovis\" javascript\n",
    "    It uses the files \"template_protoviz.html and \"protovis-r3.2.js\"\n",
    "    '''\n",
    "    nodes = g.nodes()\n",
    "    indexed_nodes = {}\n",
    "    idx = 0\n",
    "    for n in nodes:\n",
    "        indexed_nodes.update([(n, idx,)])\n",
    "        idx += 1\n",
    "    links = []\n",
    "    for n1, n2 in g.edges():\n",
    "        links.append({'source': indexed_nodes[n2],'target': indexed_nodes[n1]})\n",
    "    json_data = json.dumps({\"nodes\" : [{\"nodeName\" : n} for n in nodes], \"links\" : links}, indent=4)\n",
    "    html = open(pathtemplate).read().format(json_data,)\n",
    "    f = open(pathprotofile, 'w')\n",
    "    f.write(html)\n",
    "    f.close()\n",
    "    print >> sys.stderr, 'Graph exported for file: {}'.format(pathprotofile)\n",
    "    return f.name, html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = save_protovis_file(g_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!chromium /home/rsouza/Dropbox/Renato/ModMinDados/outputs/graph_retweet.html\n",
    "webbrowser.open(os.path.join('file://', pathprotofile))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing with Ubigraph  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://ubietylab.net/ubigraph/  \n",
    "http://docs.python.org/library/xmlrpclib.html  \n",
    "The package is quite old and is not being mantained. I left the code here just as an example for the brave!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#import xmlrpclib\n",
    "#import ubigraph\n",
    "#ubiServer = \"http://127.0.0.1:20738/RPC2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def showing_in_ubigraph(graph, vstyles=[],estyles=[]):\n",
    "    \"\"\"\n",
    "    Dynamic visualization using Ubigraph. Server should be\n",
    "    running in the URL \"ubiServer\"\n",
    "    graph.edges is a list of tuples: (n1,n2,w)\n",
    "    \"\"\"\n",
    "    U = ubigraph.Ubigraph(URL=ubiServer)\n",
    "    U.clear()\n",
    "    nodes = {}\n",
    "    edges = set([])\n",
    "    #maxw = float(max(np.array([i[2] for i in graph.edges()]))) #largest weight\n",
    "    if not vstyles:\n",
    "        vstyles = cycle([U.newVertexStyle(id=1,shape=\"sphere\", color=\"#ff0000\")])\n",
    "    else:\n",
    "        vstyles = cycle(vstyles)\n",
    "    rt_style = U.newVertexStyle(id=2,shape=\"sphere\", color=\"#00ff00\")\n",
    "    for e in graph.edges():\n",
    "        if e[0] not in nodes:\n",
    "            n1 = U.newVertex(style=vstyles.next(), label=str(e[0]))#.decode('latin-1'))\n",
    "            nodes[e[0]] = n1\n",
    "        else:\n",
    "            n1 = nodes[e[0]]\n",
    "        if e[1] not in nodes:\n",
    "            n2 = U.newVertex(style=rt_style, label=str(e[1]))\n",
    "            nodes[e[1]] = n2\n",
    "        else:\n",
    "            n2 = nodes[e[1]]\n",
    "        #es = e[2]/maxw\n",
    "        if (n1,n2) not in edges:\n",
    "            #U.newEdge(n1,n2,spline=True,strength=es, width=2.0, showstrain=True)\n",
    "            U.newEdge(n1,n2,spline=True, width=2.0, showstrain=True)\n",
    "            edges.add((n1,n2))\n",
    "            edges.add((n2,n1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
