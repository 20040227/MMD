{
 "metadata": {
  "name": "Untitled0"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Mestrado em Modelagem Matematica da Informacao\n",
      "\n",
      "Master Program - Mathematical Modeling of Information\n",
      "\n",
      "Disciplina: Modelagem e Mineracao de Dados\n",
      "\n",
      "Course: Data Mining and Modeling\n",
      "\n",
      "Professor: Renato Rocha Souza\n",
      "\n",
      "Topic: Twitter Analysis and Visualization (class #11)\n",
      "\n",
      "Information on the Python Packages used:\n",
      "\n",
      "http://code.google.com/p/python-twitter/\n",
      "\n",
      "http://networkx.lanl.gov/\n",
      "\n",
      "http://docs.python.org/library/re.html\n",
      "\n",
      "http://nltk.org/\n",
      "\n",
      "http://ubietylab.net/ubigraph/content/Docs/index.html\n",
      "\n",
      "http://docs.python.org/library/xmlrpclib.html\n",
      "\n",
      "http://docs.python.org/library/webbrowser.html\n",
      "\n",
      "http://docs.python.org/library/codecs.html\n",
      "\n",
      "http://matplotlib.sourceforge.net/\n",
      "\n",
      "http://numpy.scipy.org/\n",
      "\n",
      "http://docs.python.org/library/itertools.html\n",
      "\n",
      "http://docs.python.org/library/sys.html\n",
      "\n",
      "http://docs.python.org/library/json.html\n",
      "\n",
      "http://docs.python.org/library/os"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import twitter\n",
      "import nltk\n",
      "import re\n",
      "import networkx as nx\n",
      "import sys\n",
      "import os\n",
      "import json\n",
      "import webbrowser\n",
      "import codecs\n",
      "import xmlrpclib\n",
      "import ubigraph\n",
      "from itertools import cycle\n",
      "import numpy as np\n",
      "from matplotlib.pyplot import plot, show, title, legend, figure"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Specifying the path to the files"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "templates = \"/home/rsouza/Documentos/Git/MMD/templates/\"\n",
      "outputs = \"/home/rsouza/Documentos/outputs/\"\n",
      "\n",
      "dotfile = \"graph_retweet.dot\"\n",
      "protofile = \"graph_retweet.html\"\n",
      "tweetsfile = \"Tweets_dump.txt\"\n",
      "template_proto = 'template_protoviz.html'\n",
      "\n",
      "pathdotfile = (outputs+dotfile)\n",
      "pathprotofile = (outputs+protofile)\n",
      "pathtweetsfile = (outputs+tweetsfile)\n",
      "pathtemplate = (templates+template_proto)\n",
      "\n",
      "ubiServer = \"http://127.0.0.1:20738/RPC2\"\n",
      "\n",
      "stoplist_en = nltk.corpus.stopwords.words('english')\n",
      "stoplist_pt = nltk.corpus.stopwords.words('portuguese')\n",
      "ignorewords = stoplist_en + stoplist_pt + ['',' ','-','rt']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Twitter API Keys\n",
      "\n",
      "Please generate yours...\n",
      "\n",
      "ck = consumer_key\n",
      "\n",
      "cs = consumer_secret\n",
      "\n",
      "atk = access_token_key\n",
      "\n",
      "ats = access_token_secret\n",
      "\n",
      "https://dev.twitter.com/docs/auth/oauth\n",
      "\n",
      "https://dev.twitter.com/apps/new"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ck = ''\n",
      "cs = ''\n",
      "atk = ''\n",
      "ats = ''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Functions to access, retrieve and process Twitter Information:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def search_for_term(termo):\n",
      "    '''Search and return tweets on a subject (5 pages of 100 results each)\n",
      "    Save results in a file defined in \"pathtweetsfile\" '''\n",
      "    search_results = []\n",
      "    tweets = []\n",
      "    tweets_txt = []\n",
      "    tweets_words = []\n",
      "    names = []\n",
      "    for page in range(1,6):\n",
      "        search_results.append(api.GetSearch(term=termo, per_page=100, page=page))\n",
      "    for i in range(len(search_results)):\n",
      "        for j in range(len(search_results[i])):\n",
      "            tweets.append(search_results[i][j])\n",
      "    tweets_txt += [tweet.text.split(u' ') for tweet in tweets]\n",
      "    for i in range(len(tweets)):\n",
      "        tweets_words += [word.lower().strip(u':@&$!?') for word in tweets_txt[i]]\n",
      "    for i in range(len(tweets)): \n",
      "        names += [word.strip(u':@&$!?') for word in tweets_txt[i] if word.istitle() and len(word) > 2]\n",
      "    out = file(pathtweetsfile,'w')\n",
      "    for tweet in tweets_txt: \n",
      "        out.write(u'\\n{}'.format(tweet))\n",
      "    return tweets, tweets_txt, tweets_words, names\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def get_rt_origins(tweet):\n",
      "    ''' Regex adapted from \n",
      "    http://stackoverflow.com/questions/655903/python-regular-expression-for-retweets'''\n",
      "    rt_patterns = re.compile(r\"(RT|via)((?:\\b\\W*@\\w+)+)\", re.IGNORECASE)\n",
      "    rt_origins = []\n",
      "    try:\n",
      "        rt_origins += [mention.strip() for mention in rt_patterns.findall(tweet)[0][1].split()]\n",
      "    except IndexError, e:\n",
      "        pass\n",
      "    return [rto.strip(\"@\") for rto in rt_origins]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def create_graph_retweets(tweets):\n",
      "    g = nx.DiGraph()\n",
      "    for tweet in tweets:\n",
      "        rt_origins = get_rt_origins(tweet.text)\n",
      "        if not rt_origins:\n",
      "            continue\n",
      "        for rt_origin in rt_origins:\n",
      "            g.add_edge(rt_origin, tweet.user.screen_name, {'tweet_id': tweet.id})\n",
      "    return g"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def save_dotfile(g):\n",
      "    try:\n",
      "        nx.drawing.write_dot(g, pathdotfile)\n",
      "        print >> sys.stderr, 'Graph exported for file: {}'.format(pathdotfile)\n",
      "    except (ImportError, UnicodeEncodeError): \n",
      "        # Este bloco serve para usuarios de windows, que certamente terao problemas\n",
      "        # com o metodo nx.drawing.write_dot. Tambem serve para os casos em que temos\n",
      "        # problemas com o unicode\n",
      "        dot = ['\"{}\" -> \"{}\" [tweet_id={}]'.format(n1, n2, g[n1][n2]['tweet_id'])\n",
      "               for (n1, n2) in g.edges()]\n",
      "        f = codecs.open(pathdotfile, 'w', encoding='utf-8')\n",
      "        f.write('''strict digraph {{}}'''.format(';\\n'.join(dot), ))\n",
      "        f.close()\n",
      "        print >> sys.stderr, 'Graph exported for file: {}'.format(pathdotfile)\n",
      "        return f.name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def save_protovis_file(g):\n",
      "    '''A visualization alternative is \"protovis\" javascript\n",
      "    It uses the files \"template_protoviz.html and \"protovis-r3.2.js\"\n",
      "    '''\n",
      "    nodes = g.nodes()\n",
      "    indexed_nodes = {}\n",
      "    idx = 0\n",
      "    for n in nodes:\n",
      "        indexed_nodes.update([(n, idx,)])\n",
      "        idx += 1\n",
      "    links = []\n",
      "    for n1, n2 in g.edges():\n",
      "        links.append({'source': indexed_nodes[n2],'target': indexed_nodes[n1]})\n",
      "    json_data = json.dumps({\"nodes\" : [{\"nodeName\" : n} for n in nodes], \"links\" : links}, indent=4)\n",
      "    html = open(pathtemplate).read().format(json_data,)\n",
      "    f = open(pathprotofile, 'w')\n",
      "    f.write(html)\n",
      "    f.close()\n",
      "    print >> sys.stderr, 'Graph exported for file: {}'.format(pathprotofile)\n",
      "    return f.name"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def showing_in_ubigraph(graph, vstyles=[],estyles=[]):\n",
      "    \"\"\"\n",
      "    Dynamic visualization using Ubigraph. Server should be\n",
      "    running in the URL \"ubiServer\"\n",
      "    graph.edges is a list of tuples: (n1,n2,w)\n",
      "    \"\"\"\n",
      "    U = ubigraph.Ubigraph(URL=ubiServer)\n",
      "    U.clear()\n",
      "    nodes = {}\n",
      "    edges = set([])\n",
      "    #maxw = float(max(np.array([i[2] for i in graph.edges()]))) #largest weight\n",
      "    if not vstyles:\n",
      "        vstyles = cycle([U.newVertexStyle(id=1,shape=\"sphere\", color=\"#ff0000\")])\n",
      "    else:\n",
      "        vstyles = cycle(vstyles)\n",
      "    rt_style = U.newVertexStyle(id=2,shape=\"sphere\", color=\"#00ff00\")\n",
      "    for e in graph.edges():\n",
      "        if e[0] not in nodes:\n",
      "            n1 = U.newVertex(style=vstyles.next(), label=str(e[0]))#.decode('latin-1'))\n",
      "            nodes[e[0]] = n1\n",
      "        else:\n",
      "            n1 = nodes[e[0]]\n",
      "        if e[1] not in nodes:\n",
      "            n2 = U.newVertex(style=rt_style, label=str(e[1]))\n",
      "            nodes[e[1]] = n2\n",
      "        else:\n",
      "            n2 = nodes[e[1]]\n",
      "        #es = e[2]/maxw\n",
      "        if (n1,n2) not in edges:\n",
      "            #U.newEdge(n1,n2,spline=True,strength=es, width=2.0, showstrain=True)\n",
      "            U.newEdge(n1,n2,spline=True, width=2.0, showstrain=True)\n",
      "            edges.add((n1,n2))\n",
      "            edges.add((n2,n1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Block for Lexical Analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "goodwords =  ['Abundant','Accomplished','Achieving','Active','Admirable','Adorable',\n",
      "              'Adventurous','Admired','Affluent','Agreeable','Alert','Aligned','Alive',\n",
      "              'Amazing','Appealing','Appreciate','Artistic','Astounding','Astute',\n",
      "              'Attentive','Attractive','Auspicious','Authentic','Awake','Aware','Awesome',\n",
      "              'Beaming','Beautiful','Better','Best','Blessed','Bliss','Bold','Bright','Brilliant',\n",
      "              'Brisk','Buoyant','Calm','Capable','Centered','Certain','Charming',\n",
      "              'Cheerful','Clear','Clever','Competent','Complete','Confident','Connected',\n",
      "              'Conscious','Considerate','Convenient','Courageous','Creative','Daring',\n",
      "              'Dazzling','Delicious','Delightful','Desirable','Determined','Diligent',\n",
      "              'Discerning','Discover','Dynamic','Eager','Easy','Efficient','Effortless',\n",
      "              'Elegant','Eloquent','Energetic','Endless','Enhancing','Engaging','Enormous'\n",
      "              ,'Enterprising','Enthusiastic','Enticing','Excellent','Exceptional','Exciting'\n",
      "              ,'Experienced','Exquisite','Fabulous','Fair','Far-Sighted','Fascinating',\n",
      "              'Fine','Flattering','Flourishing','Fortunate','Free','Friendly','Fulfilled',\n",
      "              'Fun','Generous','Genuine','Gifted','Glorious','Glowing','Good','Good-Looking',\n",
      "              'Gorgeous','Graceful','Gracious','Grand','Great','Handsome','Happy','Hardy',\n",
      "              'Harmonious','Healed','Healthy','Helpful','Honest','Humorous','Ideal',\n",
      "              'Imaginative','Impressive','Industrious','Ingenious','Innovative','Inspired',\n",
      "              'Intelligent','Interested','Interesting','Intuitive','Inventive','Invincible',\n",
      "              'Inviting','Irresistible','Joyous','Judicious','Keen','Kind','Knowing','Leader',\n",
      "              'Limitless','Lively','Loving','Lucky','Luminous','Magical','Magnificent',\n",
      "              'Marvellous','Masterful','Mighty','Miraculous','Motivated','Natural','Neat',\n",
      "              'Nice','Nurturing','Noble','Optimistic','Outstanding','Passionate','Peaceful',\n",
      "              'Perfect','Persevering','Persistent','Playful','Pleasing','Plentiful','Positive',\n",
      "              'Powerful','Precious','Prepared','Productive','Profound','Prompt','Prosperous',\n",
      "              'Proud','Qualified','Quick','Radiant','Reasonable','Refined','Refreshing',\n",
      "              'Relaxing','Reliable','Remarkable','Resolute','Resourceful','Respected',\n",
      "              'Rewarding','Robust','Safe','Satisfied','Secure','Seductive','Self-Reliant',\n",
      "              'Sensational','Sensible','Sensitive','Serene','Sharing','Skilful','Smart',\n",
      "              'Smashing','Smooth','Sparkling','Spiritual','Splendid','Strong','Stunning',\n",
      "              'Successful','Superb','Swift','Talented','Tenacious','Terrific','Thankful',\n",
      "              'Thrilling','Thriving','Timely','Trusting','Truthful','Ultimate','Unique',\n",
      "              'Valiant','Valuable','Versatile','Vibrant','Victorious','Vigorous','Vivacious',\n",
      "              'Vivid','Warm','Wealthy','Well','Whole','Wise','Wonderful','Worthy','Young',\n",
      "              'Youthful','Zeal','Zest']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "badwords =   ['abandoned','abused','accused','addicted','afraid','aggravated',\n",
      "              'aggressive','alone','angry','anguish','annoyed','anxious','apprehensive',\n",
      "              'argumentative','artificial','ashamed','assaulted','at a loss','at risk',\n",
      "              'atrocious','attacked','avoided','awful','awkward','bad','badgered','baffled',\n",
      "              'banned','barren','beat','beaten down','belittled','berated','betrayed',\n",
      "              'bitched at','bitter','bizzare','blacklisted','blackmailed','blamed','bleak',\n",
      "              'blown away','blur','bored','boring','bossed-around','bothered','bothersome',\n",
      "              'bounded','boxed-in','broken','bruised','brushed-off','bugged','bullied',\n",
      "              'bummed','bummed out','burdened','burdensome','burned','burned-out',\n",
      "              'caged in','careless','chaotic','chased','cheated','cheated on','chicken',\n",
      "              'claustrophobic','clingy','closed','clueless','clumsy','coaxed',\n",
      "              'codependent','coerced','cold','cold-hearted','combative','commanded',\n",
      "              'compared','competitive','compulsive','conceited','concerned',\n",
      "              'condescended to','confined','conflicted','confronted','confused',\n",
      "              'conned','consumed','contemplative','contempt','contentious','controlled',\n",
      "              'convicted','cornered','corralled','cowardly','crabby','cramped','cranky',\n",
      "              'crap','crappy','crazy','creeped out','creepy','critical','criticized',\n",
      "              'cross','crowded','cruddy','crummy','crushed','cut-down','cut-off','cynical',\n",
      "              'damaged','damned','dangerous','dark','dazed','dead','deceived','deep',\n",
      "              'defamed','defeated','defective','defenseless','defensive','defiant',\n",
      "              'deficient','deflated','degraded','dehumanized','dejected','delicate',\n",
      "              'deluded','demanding','demeaned','demented','demoralized','demotivated',\n",
      "              'dependent','depleted','depraved','depressed','deprived','deserted',\n",
      "              'deserving of pain/punishment','desolate','despair','despairing',\n",
      "              'desperate','despicable','despised','destroyed','destructive',\n",
      "              'detached','detest','detestable','detested','devalued','devastated',\n",
      "              'deviant','devoid','diagnosed','dictated to','different','difficult',\n",
      "              'directionless','dirty','disabled','disagreeable','disappointed',\n",
      "              'disappointing','disapproved of','disbelieved','discardable','discarded',\n",
      "              'disconnected','discontent','discouraged','discriminated','disdain',\n",
      "              'disdainful','disempowered','disenchanted','disgraced','disgruntled',\n",
      "              'disgust','disgusted','disheartened','dishonest','dishonorable',\n",
      "              'disillusioned','dislike','disliked','dismal','dismayed','disorganized',\n",
      "              'disoriented','disowned','displeased','disposable','disregarded',\n",
      "              'disrespected','dissatisfied','distant','distracted','distraught',\n",
      "              'distressed','disturbed','dizzy','dominated','doomed','double-crossed',\n",
      "              'doubted','doubtful','down','down and out','down in the dumps',\n",
      "              'downhearted','downtrodden','drained','dramatic','dread','dreadful',\n",
      "              'dreary','dropped','drunk','dry','dumb','dumped','dumped on','duped',\n",
      "              'edgy','egocentric','egotistic','egotistical','elusive','emancipated',\n",
      "              'emasculated','embarrassed','emotional','emotionless','emotionally bankrupt',\n",
      "              'empty','encumbered','endangered','enraged','enslaved','entangled','evaded',\n",
      "              'evasive','evicted','excessive','excluded','exhausted','exploited','exposed',\n",
      "              'fail','failful','fake','false','fear','fearful','fed up','flawed','forced',\n",
      "              'forgetful','forgettable','forgotten','fragile','freaked out','frightened',\n",
      "              'frigid','frustrated','furious','gloomy','glum','gothic','grey','grief','grim',\n",
      "              'gross','grossed-out','grotesque','grouchy','grounded','grumpy','guilt-tripped',\n",
      "              'guilty','harassed','hard','hard-hearted','harmed','hassled','hate','hateful',\n",
      "              'hatred','haunted','heartbroken','heartless','heavy-hearted','helpless',\n",
      "              'hesitant','hideous','hindered','hopeless','horrible','horrified','horror',\n",
      "              'hostile','hot-tempered','humiliated','hung up','hung over','hurried','hurt',\n",
      "              'hysterical','idiot','idiotic','ignorant','ignored','ill','ill-tempered',\n",
      "              'imbalanced','imposed-upon','impotent','imprisoned','impulsive','in the dumps',\n",
      "              'in the way','inactive','inadequate','incapable','incommunicative','incompetent',\n",
      "              'incompatible','incomplete','incorrect','indecisive','indifferent',\n",
      "              'indoctrinated','inebriated','ineffective','inefficient','inferior',\n",
      "              'infuriated','inhibited','inhumane','injured','injusticed','insane',\n",
      "              'insecure','insignificant','insincere','insufficient','insulted',\n",
      "              'intense','interrogated','interrupted','intimidated','intoxicated',\n",
      "              'invalidated','invisible','irrational','irritable','irritated',\n",
      "              'isolated','jaded','jealous','jerked around','joyless','judged',\n",
      "              'kept apart','kept away','kept in','kept out','kept quiet','labeled',\n",
      "              'laughable','laughed at','lazy','leaned on','lectured to','left out',\n",
      "              'let down','lied about','lied to','limited','little','lonely','lonesome',\n",
      "              'longing','lost','lousy','loveless','low','mad','made fun of','man handled',\n",
      "              'manipulated','masochistic','messed with','messed up','messy','miffed',\n",
      "              'miserable','misled','mistaken','mistreated','mistrusted','misunderstood',\n",
      "              'mixed-up','mocked','molested','moody','nagged','needy','negative',\n",
      "              'nervous','neurotic','nonconforming','numb','nuts','nutty','objectified',\n",
      "              'obligated','obsessed','obsessive','obstructed','odd','offended',\n",
      "              'on display','opposed','oppressed','out of place','out of touch',\n",
      "              'over-controlled','over-protected','overwhelmed','pain','panic','paranoid',\n",
      "              'passive','pathetic','pessimistic','petrified','phony','picked on','pissed',\n",
      "              'pissed off','plain','played with','pooped','poor','powerless','pre-judged',\n",
      "              'preached to','preoccupied','predjudiced','pressured','prosecuted',\n",
      "              'provoked','psychopathic','psychotic','pulled apart','pulled back',\n",
      "              'punished','pushed','pushed away','put down','puzzled','quarrelsome',\n",
      "              'queer','questioned','quiet','rage','raped','rattled','regret','rejected',\n",
      "              'resented','resentful','responsible','retarded','revengeful','ridiculed',\n",
      "              'ridiculous','robbed','rotten','sad','sadistic','sarcastic','scared',\n",
      "              'scarred','screwed','screwed over','screwed up','self-centered','self-conscious',\n",
      "              'self-destructive','self-hatred','selfish','sensitive','shouted at','shy',\n",
      "              'singled-out','slow','small','smothered','snapped at','spiteful','stereotyped',\n",
      "              'strange','stressed','stretched','stuck','stupid','submissive','suffering',\n",
      "              'suffocated','suicidal','superficial','suppressed','suspicious','worse','worst'\n",
      "              ,'bankrupcy','jobs','shit','socialism','#sob']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def lexical_diversity(text):\n",
      "    return len(text) / len(set(text))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def percentage(count, total):\n",
      "    return 100 * count / total"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def sentiment_analysis(texto, goodwords, badwords):\n",
      "    '''\n",
      "    Not a sophisticated one, but the main idea is present.\n",
      "    Please read: http://alias-i.com/lingpipe/demos/tutorial/sentiment/read-me.html\n",
      "    '''\n",
      "    goodness = 0\n",
      "    badness = 0    \n",
      "    for word in goodwords:\n",
      "        goodness += percentage(texto.count(word.lower()), len(texto))\n",
      "    for word in badwords:\n",
      "        badness += percentage(texto.count(word.lower()), len(texto))\n",
      "    print 'Grau de negatividade: {}'.format(badness)\n",
      "    print 'Grau de positividade: {}'.format(goodness)\n",
      "    return goodness, badness"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Acessing Twitter (with or withou authentication)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#api = twitter.Api() # Accessing with no authentication\n",
      "api = twitter.Api(consumer_key = ck, consumer_secret = cs, access_token_key = atk, access_token_secret = ats)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Recent public messages"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "msgpublicas = api.GetPublicTimeline() \n",
      "print([s.user.name for s in msgpublicas])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Recent messages from an user"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "msguser = api.GetUserTimeline('rrsouza')\n",
      "print([s.text for s in msguser])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Searching for a term in tweets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "search = api.GetSearch('Petrobras')\n",
      "print([s.text for s in search])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "After authentication, more options are available"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "userfollow = api.GetFriends()\n",
      "print([u.name for u in userfollow])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "userfollowers = api.GetFollowers()\n",
      "print([u.name for u in userfollowers])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "userfriendstimeline = api.GetFriendsTimeline()\n",
      "print([u.text for u in userfriendstimeline])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Using our customized function that retrieves 5 x 100 tweets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tweets, tweets_txt, tweets_words, names = search_for_term(u'London')          \n",
      "    \n",
      "print('Word count: {}'.format(len(tweets_words)))\n",
      "print('Repertoire: {}'.format(len(set(tweets_words))))\n",
      "print('Lexical diversity: {}'.format(lexical_diversity(tweets_words)))\n",
      "    \n",
      "freq_dist = nltk.FreqDist(tweets_words)\n",
      "freq_dist.plot(40)\n",
      "#freq_dist.plot(40, cumulative = True)    \n",
      "    \n",
      "print('10 most frequent words')\n",
      "print(freq_dist.keys()[:10])\n",
      "print('10 less frequent words')\n",
      "print(freq_dist.keys()[-10:])\n",
      "print('Sorted list of words')\n",
      "print(sorted(set(tweets_words)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Same as before, without stopwords. See variable \"ignorewords"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_tweets_words = [word for word in tweets_words if word not in ignorewords]\n",
      "    \n",
      "freq_new = nltk.FreqDist(new_tweets_words)    \n",
      "freq_new.plot()\n",
      "freq_new.plot(40)\n",
      "freq_new.plot(40, cumulative = True)\n",
      "    \n",
      "print('10 most frequent words')\n",
      "print(freq_new.keys()[:10])\n",
      "print('10 less frequent words')\n",
      "print(freq_new.keys()[-10:])\n",
      "print('Sorted list of words')\n",
      "print(sorted(set(new_tweets_words)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Counting specific words"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "new_tweets_words.count('bad')\n",
      "new_tweets_words.count('good')\n",
      "freq_new['good'] #same as before\n",
      "freq_new.freq('good') #relative to the others"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Eliminating small words"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigger_tweets_words = [word for word in new_tweets_words if len(word) > 2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Words with specific sizes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mediumsized_tweets_words = [word for word in new_tweets_words if len(word) > 2 and len(word) < 9]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Citation Analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "citacoes = [word for word in tweets_words if word.startswith('@')]\n",
      "freq_citacoes = nltk.FreqDist(citacoes)\n",
      "freq_citacoes.items()\n",
      "freq_citacoes.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Hashtag Analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "hashtags = [word for word in tweets_words if word.startswith('#')]\n",
      "freq_hashtags = nltk.FreqDist(hashtags)\n",
      "freq_hashtags.items()\n",
      "freq_hashtags.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Analysis of Frequent words\n",
      "\n",
      "Can be used with any of the previous lists'''"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "frequent_words = [word.lower() for word in new_tweets_words if tweets_words.count(word) > 5]\n",
      "freq_dist2 = nltk.FreqDist(frequent_words)\n",
      "freq_dist2.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Words Sizes"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "freqtamwords = nltk.FreqDist([len(w) for w in new_tweets_words])\n",
      "freqtamwords.items()\n",
      "freqtamwords.plot()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Bigrams"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "bigramas_tweets = nltk.bigrams(new_tweets_words)\n",
      "freqbig = nltk.FreqDist(bigramas_tweets)\n",
      "freqbig.plot(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Names (capitalized words)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "freq_names = nltk.FreqDist(names)\n",
      "freq_names.plot(20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Sentiment Analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sentiment_analysis(tweets_words, goodwords, badwords)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Graphs\n",
      "   \n",
      "Obs: To generate a png graph from the dotfile, type in the Unix Prompt: \n",
      "'circo -Tpng -Gcharset=latin1 -Ograph_retweet graph_retweet.dot'"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g_rt = create_graph_retweets(tweets)\n",
      "#print(g_rt.number_of_nodes())\n",
      "#print(g_rt.number_of_edges())\n",
      "#print(nx.degree(g_rt))\n",
      "dic = nx.degree(g_rt)\n",
      "#print(sorted(dic.values()))\n",
      "plot(sorted(dic.values()))\n",
      "save_dotfile(g_rt)\n",
      "save_protovis_file(g_rt)\n",
      "showing_in_ubigraph(g_rt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}