{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mestrado em Modelagem Matematica da Informacao\n",
    "----------------------------------------------\n",
    "Disciplina: Modelagem e Mineracao de Dados\n",
    "------------------------------------------\n",
    "\n",
    "Master Program - Mathematical Modeling of Information\n",
    "-----------------------------------------------------\n",
    "Course: Data Mining and Modeling\n",
    "--------------------------------\n",
    "\n",
    "Professor: Renato Rocha Souza\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic: Classification and Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information on the Python Packages used:  \n",
    "http://docs.python.org/library/sqlite3.html  \n",
    "http://docs.python.org/library/re.html  \n",
    "http://www.feedparser.org/  \n",
    "http://docs.python.org/2/library/tkinter.html  \n",
    "http://www.tkdocs.com/tutorial/index.html  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import math\n",
    "import feedparser\n",
    "import time\n",
    "import string\n",
    "import datetime\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specifying the path to the files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "outputs = \"../outputs/\"\n",
    "\n",
    "dbfile1 = \"treino.sqlite\"\n",
    "dbfile2 = \"treinoblogs.sqlite\"\n",
    "outblog = \"blogoutputrss.xml\"\n",
    "\n",
    "db_teste = os.path.join(outputs,dbfile1)\n",
    "db_blog = os.path.join(outputs,dbfile2)\n",
    "rssblogoutput = os.path.join(outputs,outblog)\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese') + nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### First block of functions: feature extraction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def getwords(html):\n",
    "    '''Remove the HTML tags and cleans the feeds files;splits the sentences \n",
    "    by the non alpha characters and converts all words to lowercase.\n",
    "    Ignores bigger and too small words'''\n",
    "    #splitter = re.compile('\\\\W*', flags=re.U)\n",
    "    #splitter=re.compile(r'[^A-Z^a-z]+', flags=re.U)\n",
    "    #words=[s.lower() for s in splitter.split(html) if len(s)>2 and len(s)<20]\n",
    "    words = BeautifulSoup(html, \"lxml\").findAll(text=True)[0].split()\n",
    "    words = [w.strip(string.punctuation) for w in words if len(w)>2 and len(w)<20 and w not in stopwords]\n",
    "    return dict([(w,1) for w in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def entryfeatures(entry):\n",
    "    '''Used when our features are not documents, but feeds rss'''\n",
    "    splitter=re.compile('\\\\W*')\n",
    "    f={}\n",
    "    # Extract title words\n",
    "    titlewords=[s.lower() for s in splitter.split(entry['title']) if len(s)>2 and len(s)<20 and s not in stopwords]\n",
    "    for w in titlewords: f['Title:'+w]=1\n",
    "    # Extract summary words\n",
    "    summarywords=[s.lower() for s in splitter.split(entry['summary']) if len(s)>2 and len(s)<20 and s not in stopwords]\n",
    "    # Count lowercase words\n",
    "    uc=0\n",
    "    for i in range(len(summarywords)):\n",
    "        w=summarywords[i]\n",
    "        f[w]=1\n",
    "        if w.isupper(): uc+=1\n",
    "        # Features are words in the feed summary\n",
    "        if i < len(summarywords)-1:\n",
    "            twowords=' '.join(summarywords[i:i+1])\n",
    "            f[twowords]=1\n",
    "    # Save publisher information\n",
    "    f['Publisher:'+entry['publisher']]=1\n",
    "    # Too many uppercase words are indicated\n",
    "    if float(uc)/len(summarywords)>0.3:\n",
    "        f['MAIUSCULAS']=1\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Second block of functions: classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class classifier:\n",
    "    ''' Represents the classifier, storing what's learnt from training.\n",
    "    fc saves the combination words/categories {'word': {'bad': 3, 'good': 2}}\n",
    "    and cc is a dictionary that stores the number of times a category was used\n",
    "    {'bad': 3, 'good': 2}. Will be used when no DB is used.\n",
    "    Getfeatures is the feature extraction function to be used'''\n",
    "    def __init__(self, getfeatures, filename=None, usedb=False):\n",
    "        self.fc={}\n",
    "        self.cc={}\n",
    "        self.getfeatures = getfeatures\n",
    "        self.usedb = usedb\n",
    "    \n",
    "    def setdb(self,dbfile):\n",
    "        '''When using a database and not dictionaries, to persist the information\n",
    "        across sessions'''\n",
    "        self.con = sqlite3.dbapi2.connect(dbfile)    \n",
    "        self.con.execute(u'CREATE TABLE IF NOT EXISTS fc(feature,category,count)')\n",
    "        self.con.execute(u'CREATE TABLE IF NOT EXISTS cc(category,count)')\n",
    "\n",
    "    def fcount(self,f,cat):\n",
    "        '''Returns the number of times a feature appears in a category'''\n",
    "        if not self.usedb:\n",
    "            if f in self.fc and cat in self.fc[f]: \n",
    "                return float(self.fc[f][cat])\n",
    "            else: \n",
    "                return 0\n",
    "        else:\n",
    "            query = u'SELECT COUNT(*) FROM fc WHERE feature=? AND category=?'\n",
    "            res = self.con.execute(query,(f,cat)).fetchone()\n",
    "            if res == None: \n",
    "                return 0\n",
    "            else: \n",
    "                return float(res[0])\n",
    "\n",
    "    def incf(self,f,cat):\n",
    "        '''Creates a feature/category pair if not exists, or increase the number\n",
    "        if feature exists in a category'''\n",
    "        if not self.usedb:\n",
    "            self.fc.setdefault(f,{})\n",
    "            self.fc[f].setdefault(cat,0)\n",
    "            self.fc[f][cat] += 1\n",
    "        else:\n",
    "            count=self.fcount(f,cat)\n",
    "            if count == 0:\n",
    "                self.con.execute(u'INSERT INTO fc VALUES (?,?,?)',(f,cat,1))\n",
    "            else:\n",
    "                query = u'UPDATE fc SET COUNT=? WHERE feature=? AND category=?'\n",
    "                self.con.execute(query,(count+1,f,cat)) \n",
    "\n",
    "    def incc(self,cat):\n",
    "        '''Increases the number of occurrences of a category'''\n",
    "        if not self.usedb:\n",
    "            self.cc.setdefault(cat,0)\n",
    "            self.cc[cat] += 1        \n",
    "        else:\n",
    "            count=self.catcount(cat)\n",
    "            if count == 0:\n",
    "                self.con.execute(u'INSERT INTO cc VALUES (?,?)',(cat,1))\n",
    "            else:\n",
    "                query = u'UPDATE cc SET count=? WHERE category=?'\n",
    "                self.con.execute(query,(count+1,cat))    \n",
    "\n",
    "    def catcount(self,cat):\n",
    "        '''Counts the numer of itens in a category'''\n",
    "        if not self.usedb:\n",
    "            if cat in self.cc:\n",
    "                return float(self.cc[cat])\n",
    "            else:\n",
    "                return 0\n",
    "        else:\n",
    "            query = u\"SELECT COUNT(*) FROM cc WHERE category=?\"\n",
    "            res=self.con.execute(query,(cat,)).fetchone()\n",
    "            if res == None:\n",
    "                return 0\n",
    "            else:\n",
    "                return float(res[0])\n",
    "\n",
    "    def categories(self):\n",
    "        '''Lists all the categories'''        \n",
    "        if not self.usedb: return self.cc.keys()\n",
    "        else:\n",
    "            cur=self.con.execute(u'SELECT category FROM cc');\n",
    "            return [d[0] for d in cur]\n",
    "\n",
    "    def totalcount(self):\n",
    "        ''' Returns the total numer of itens'''\n",
    "        if not self.usedb: return sum(self.cc.values())\n",
    "        else:\n",
    "            res=self.con.execute(u'SELECT SUM(count) FROM cc').fetchone();\n",
    "            if res==None: return 0\n",
    "            else: return res[0]\n",
    "\n",
    "    def train(self,item,cat):\n",
    "        '''Receives an item (a bag of features) and a category, and increases\n",
    "        the relative number of this category for all the features'''\n",
    "        features=self.getfeatures(item)\n",
    "        for f in features:\n",
    "            self.incf(f,cat)\n",
    "        self.incc(cat)\n",
    "        if self.usedb: self.con.commit()\n",
    "\n",
    "    def fprob(self,f,cat):\n",
    "        '''Calculates the probability of a feature to be within a category'''\n",
    "        if self.catcount(cat)== 0:\n",
    "            return 0\n",
    "        return self.fcount(f,cat)/float(self.catcount(cat))\n",
    "\n",
    "    def weightedprob(self,f,cat,prf,weight=1.0,ap=0.5):\n",
    "        '''Calculates the probability of a feature to appear in a certain category\n",
    "        as fprob does, but assuming an initial value and changing according to \n",
    "        the training. That minimizes the effect of a rare word to be classified\n",
    "        erroneously'''\n",
    "        basicprob=prf(f,cat)\n",
    "        totals=sum([self.fcount(f,c) for c in self.categories()])\n",
    "        bp=((weight*ap)+(totals*basicprob))/(weight+totals)\n",
    "        return bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class naivebayes(classifier):\n",
    "    '''Extends classifier class overriding __init__ and adding specific functions\n",
    "    to classify documents using naive bayes'''\n",
    "    \n",
    "    def __init__(self, getfeatures, usedb=False):\n",
    "        classifier.__init__(self,getfeatures)\n",
    "        self.thresholds = {}\n",
    "        self.usedb = usedb\n",
    "        \n",
    "    def docprob(self,item,cat):\n",
    "        '''Calculates the probability of a document to be within a given\n",
    "        category multiplying all the features probabilities to be in this category'''\n",
    "        features=self.getfeatures(item)\n",
    "        p=1\n",
    "        for f in features: \n",
    "            p*=self.weightedprob(f,cat,self.fprob)\n",
    "        return p\n",
    "\n",
    "    def prob(self,item,cat):\n",
    "        catprob=self.catcount(cat)/float(self.totalcount())\n",
    "        docprob=self.docprob(item,cat)\n",
    "        return docprob*catprob\n",
    "\n",
    "    def setthreshold(self,cat,t):\n",
    "        self.thresholds[cat]=t\n",
    "\n",
    "    def getthreshold(self,cat):\n",
    "        if cat not in self.thresholds: \n",
    "            return 1.0\n",
    "        return self.thresholds[cat]\n",
    "\n",
    "    def classify(self, item, default=None):\n",
    "        '''Finds the most probably category to be set, and apply this\n",
    "        classification, given that it satisfies a minimum threshold, compared\n",
    "        to the second best category to classify; otherwise sets to \"None\"'''        \n",
    "        probs = {}\n",
    "        maximum = 0.0\n",
    "        #best = None\n",
    "        for cat in self.categories():\n",
    "            probs[cat] = self.prob(item, cat)\n",
    "            if probs[cat] > maximum: \n",
    "                maximum = probs[cat]\n",
    "                best = cat\n",
    "        for cat in probs:\n",
    "            if cat == best:\n",
    "                continue\n",
    "            if probs[cat]*self.getthreshold(best) > probs[best]: \n",
    "                return default\n",
    "        return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class fisherclassifier(classifier):\n",
    "    '''Extends classifier class overriding __init__ and adding specific functions\n",
    "    to classify documents using fisher method'''\n",
    "\n",
    "    def __init__(self,getfeatures, usedb=False):\n",
    "        classifier.__init__(self, getfeatures)\n",
    "        self.minimums = {}\n",
    "        self.usedb = usedb\n",
    "        \n",
    "    def cprob(self,f,cat):\n",
    "        '''Returns the frequency of the feature in a category divided\n",
    "        by the frequency in all categories'''\n",
    "        clf=self.fprob(f,cat)\n",
    "        if clf == 0:\n",
    "            return 0\n",
    "        freqsum=sum([self.fprob(f,c) for c in self.categories()])\n",
    "        p=float(clf)/(freqsum)\n",
    "        return p\n",
    "\n",
    "    def invchi2(self,chi, df):\n",
    "        m = chi / 2.0\n",
    "        sum = term = math.exp(-m)\n",
    "        for i in range(1, df//2):\n",
    "            term *= m / i\n",
    "            sum += term\n",
    "        return min(sum, 1.0)\n",
    "\n",
    "    def prob(self,item,cat):\n",
    "        '''Multipy all the categories, applies the natural log\n",
    "        and uses the inverse chi2 to calculate probabilty'''\n",
    "        p = 1\n",
    "        features = self.getfeatures(item)\n",
    "        for f in features:\n",
    "            p *= (self.weightedprob(f,cat,self.cprob))\n",
    "        fscore = -2*math.log(p)\n",
    "        return self.invchi2(fscore,len(features)*2)\n",
    "\n",
    "    def setminimum(self,cat, minimum):\n",
    "        self.minimums[cat] = minimum\n",
    "\n",
    "    def getminimum(self,cat):\n",
    "        if cat not in self.minimums: return 0\n",
    "        return self.minimums[cat]\n",
    "\n",
    "    def classify(self, item, default=None):\n",
    "        '''Applies fisher to all categories to find the best result, given \n",
    "        that it satisfies a minimum threshold, otherwise sets to \"None\"'''\n",
    "        best = default\n",
    "        maximum = 0.0\n",
    "        for c in self.categories():\n",
    "            p = self.prob(item,c)\n",
    "            if p>self.getminimum(c) and p > maximum:\n",
    "                best = c\n",
    "                maximum = p\n",
    "        return best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Third block of functions: reading files or searching for feeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def blogread(file_or_subject, classifier, search=True):\n",
    "    '''Receives an url to search Google for blogs in a given subject, or a \n",
    "    rss xml file with saved feeds. Tries to classify the entries'''\n",
    "    if search:\n",
    "        generic = 'https://www.google.com.br/search?hl=pt-BR&gl=br&tbm=nws&authuser=0&q={}&oq={}'\n",
    "        url = generic.format(file_or_subject,file_or_subject)\n",
    "        f = feedparser.parse(url)\n",
    "    else:\n",
    "        f = feedparser.parse(file_or_subject)\n",
    "    for entry in f['entries']:\n",
    "        print(u'\\n-----')\n",
    "        print(u'Title:     '+ entry['title'])\n",
    "        print(u'Publisher: '+ entry['publisher'])\n",
    "        print(u'Date Published: ',datetime.datetime.fromtimestamp(time.mktime(entry['updated_parsed'])))\n",
    "        print(u'\\n-----')        \n",
    "        print(entry['summary'])\n",
    "        guess = classifier.classify(entry)\n",
    "        print(u'Suggested: {}'.format(guess))\n",
    "        cl = raw_input('Enter category or press <enter> to accept suggestion: ').lower() #does not work in Ipython Notebook\n",
    "        txt = 'Title:     '+entry['title']\n",
    "        txt = txt+u'\\n'+u'Publisher: '+entry['publisher']\n",
    "        txt = txt+u'\\n'+entry['summary']\n",
    "        txt = txt+u'\\n'+u'Suggested: {}'.format(guess)\n",
    "        if cl == ''.strip() and guess:\n",
    "            cl = guess\n",
    "        print(u'Category \"{}\" chosen'.format(cl))\n",
    "        classifier.train(entry,cl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fourth block of functions: instantiating and training classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sampletrain(cl):\n",
    "    print('Running sampletrain to train the classifier...')\n",
    "    cl.train('Nobody owns the water.','good')\n",
    "    cl.train('the quick rabbit jumps fences','good')\n",
    "    cl.train('buy pharmaceuticals now','bad')\n",
    "    cl.train('make quick money at the online casino','bad')\n",
    "    cl.train('the quick brown fox jumps','good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def probabilidades_palavras():\n",
    "    cl = classifier(getwords)\n",
    "    print('\\n')    \n",
    "    sampletrain(cl)\n",
    "    \n",
    "    print('How many times \"quick\" --> \"good\": {}'.format(cl.fcount('quick','good')))\n",
    "    print('How many times \"quick\" --> \"bad\": {}'.format(cl.fcount('quick','bad')))\n",
    "    print('\\nProbability of \"quick\" given that \"good\": {}'.format(cl.fprob('quick','good')))\n",
    "    print('Probability of \"money\" given that \"good\" (fprob): {}'.format(cl.fprob('money','good')))\n",
    "    print('Weighted probability of \"money\" given that \"good\" (weightedprob): {}'.format(cl.weightedprob('money','good',cl.fprob)))\n",
    "\n",
    "    print('\\nTraining again with the same documents...\\n')\n",
    "    sampletrain(cl)\n",
    "\n",
    "    print('\\nProbability of \"money\" given that \"good\" (fprob): {}'.format(cl.fprob('money','good')))\n",
    "    print('Weighted probability of \"money\" given that \"good\" (weightedprob): {}\\n'.format(cl.weightedprob('money','good',cl.fprob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running sampletrain to train the classifier...\n",
      "How many times \"quick\" --> \"good\": 2.0\n",
      "How many times \"quick\" --> \"bad\": 1.0\n",
      "\n",
      "Probability of \"quick\" given that \"good\": 0.6666666666666666\n",
      "Probability of \"money\" given that \"good\" (fprob): 0.0\n",
      "Weighted probability of \"money\" given that \"good\" (weightedprob): 0.25\n",
      "\n",
      "Training again with the same documents...\n",
      "\n",
      "Running sampletrain to train the classifier...\n",
      "\n",
      "Probability of \"money\" given that \"good\" (fprob): 0.0\n",
      "Weighted probability of \"money\" given that \"good\" (weightedprob): 0.16666666666666666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "probabilidades_palavras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def probabilidades_documentos_bayes():\n",
    "    cl = naivebayes(getwords)\n",
    "    print('\\n')    \n",
    "    sampletrain(cl)\n",
    "    \n",
    "    print('Classifying \"quick rabbit\": {}'.format(cl.classify('quick rabbit', default='unknown')))\n",
    "    print('Classifying \"quick money\": {}'.format(cl.classify('quick money', default='unknown')))\n",
    "    \n",
    "    print('\\nSetting the threshold up...')\n",
    "    cl.setthreshold('bad',3.0)\n",
    "\n",
    "    print('Classifying \"quick money\": {}'.format(cl.classify('quick money', default='unknown')))\n",
    "    \n",
    "    print('\\nTraining again with the same documents (10x)...')\n",
    "    for i in range(10): sampletrain(cl)\n",
    "    \n",
    "    print('\\nClassifying \"quick money\": {}'.format(cl.classify('quick money', default='unknown')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running sampletrain to train the classifier...\n",
      "Classifying \"quick rabbit\": good\n",
      "Classifying \"quick money\": bad\n",
      "\n",
      "Setting the threshold up...\n",
      "Classifying \"quick money\": unknown\n",
      "\n",
      "Training again with the same documents (10x)...\n",
      "Running sampletrain to train the classifier...\n",
      "Running sampletrain to train the classifier...\n",
      "Running sampletrain to train the classifier...\n",
      "Running sampletrain to train the classifier...\n",
      "Running sampletrain to train the classifier...\n",
      "Running sampletrain to train the classifier...\n",
      "Running sampletrain to train the classifier...\n",
      "Running sampletrain to train the classifier...\n",
      "Running sampletrain to train the classifier...\n",
      "Running sampletrain to train the classifier...\n",
      "\n",
      "Classifying \"quick money\": bad\n"
     ]
    }
   ],
   "source": [
    "probabilidades_documentos_bayes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def probabilidades_palavras_fisher():\n",
    "    cl = fisherclassifier(getwords)\n",
    "    print('\\n')    \n",
    "    sampletrain(cl)\n",
    "    print('\\n')      \n",
    "    print('Probability of \"quick\" given that \"good\": {}'.format(cl.cprob('quick', 'good')))\n",
    "    print('Probability of \"money\" given that \"bad\": {}'.format(cl.cprob('money', 'bad')))\n",
    "    print('Weighted probability of  \"money\" given that \"bad\": {}'.format(cl.weightedprob('money','bad',cl.cprob)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running sampletrain to train the classifier...\n",
      "\n",
      "\n",
      "Probability of \"quick\" given that \"good\": 0.5714285714285715\n",
      "Probability of \"money\" given that \"bad\": 1.0\n",
      "Weighted probability of  \"money\" given that \"bad\": 0.75\n"
     ]
    }
   ],
   "source": [
    "probabilidades_palavras_fisher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def probabilidades_documentos_fisher():\n",
    "    cl = fisherclassifier(getwords)\n",
    "    print('\\n')    \n",
    "    sampletrain(cl)\n",
    "\n",
    "    print('Classifying \"quick rabbit\": {}'.format(cl.classify('quick rabbit')))\n",
    "    print('Classifying \"quick money\": {}'.format(cl.classify('quick money')))\n",
    "   \n",
    "    print('\\nSetting the threshold up...')\n",
    "    cl.setminimum('bad',0.8)\n",
    "    print('Classifying \"quick money\": {}'.format(cl.classify('quick money')))\n",
    "\n",
    "    print('\\nSetting the threshold down...')\n",
    "    cl.setminimum('bad',0.4)\n",
    "    print('Classifying \"quick money\": {}'.format(cl.classify('quick money')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Running sampletrain to train the classifier...\n",
      "Classifying \"quick rabbit\": good\n",
      "Classifying \"quick money\": bad\n",
      "\n",
      "Setting the threshold up...\n",
      "Classifying \"quick money\": good\n",
      "\n",
      "Setting the threshold down...\n",
      "Classifying \"quick money\": bad\n"
     ]
    }
   ],
   "source": [
    "probabilidades_documentos_fisher()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def using_db_example():\n",
    "    '''Training with a classifier, persisting in a database\n",
    "    using the training data to classify using another classifier'''\n",
    "    print('\\nInstantiating a fisher classifier...')\n",
    "    cl = fisherclassifier(getwords, usedb=True)\n",
    "    cl.setdb(db_teste)\n",
    "    sampletrain(cl)\n",
    "    print('\\nInstantiating a naive bayes classifier...')    \n",
    "    cl2 = naivebayes(getwords, usedb=True)\n",
    "    cl2.setdb(db_teste)\n",
    "    print('Classifying \"quick money\": {}'.format(cl2.classify('quick money')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Instantiating a fisher classifier...\n",
      "Running sampletrain to train the classifier...\n",
      "\n",
      "Instantiating a naive bayes classifier...\n",
      "Classifying \"quick money\": bad\n"
     ]
    }
   ],
   "source": [
    "using_db_example()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def classifying_blogs(subject='Brasil'):\n",
    "    '''Instantiating a new classifier using \"entryfeatures\" (for feeds)\n",
    "    Creating the database for the persistance of training data\n",
    "    Using blogread with searching feeds option - no file reading'''\n",
    "    cl = fisherclassifier(entryfeatures, usedb=True)\n",
    "    cl.setdb(db_blog)\n",
    "    if not subject:\n",
    "        subject = input('\\n\\nPlease enter a subject to search for feeds: ').lower()\n",
    "    blogread(subject, cl) \n",
    "    print('\\nList of categories stored in the database:')\n",
    "    for category in cl.categories(): \n",
    "        print(category)\n",
    "    return cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "List of categories stored in the database:\n"
     ]
    }
   ],
   "source": [
    "cl = classifying_blogs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do some tests now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#cl.cprob(<word>,<category>)\n",
    "print(cl.cprob(u'corrupção','petrobras'))\n",
    "\n",
    "#cl.fprob(<word>,<category>)\n",
    "print(cl.fprob('fields','ciencia'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
