{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mestrado em Modelagem Matematica da Informacao\n",
    "----------------------------------------------\n",
    "Disciplina: Modelagem e Mineracao de Dados\n",
    "------------------------------------------\n",
    "\n",
    "Master Program - Mathematical Modeling of Information\n",
    "-----------------------------------------------------\n",
    "Course: Data Mining and Modeling\n",
    "--------------------------------\n",
    "\n",
    "Professor: Renato Rocha Souza\n",
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topic: Geographical and Spatial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rsouza/python/3/venv/local/lib/python3.5/site-packages/nltk/decorators.py:59: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  regargs, varargs, varkwargs, defaults = inspect.getargspec(func)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import twitter\n",
    "import nltk\n",
    "import re\n",
    "import networkx as nx\n",
    "import sys\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "from itertools import chain\n",
    "import urllib\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import webbrowser\n",
    "import codecs\n",
    "from itertools import cycle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopy.geocoders as gg\n",
    "from nominatim import Nominatim\n",
    "import Levenshtein\n",
    "from bs4 import BeautifulSoup\n",
    "from IPython.display import Image, HTML, IFrame, FileLink, FileLinks #needed to render in notebook\n",
    "from IPython.core.display import display\n",
    "#import pydot  #Install http://www.graphviz.org/ & https://pypi.python.org/pypi/pydot2/1.0.32 pydot --> pip install pydot2\n",
    "\n",
    "%matplotlib inline\n",
    "# Set default figure size for this notebook\n",
    "plt.rcParams['figure.figsize'] = (16.0, 12.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying the path to the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "templates = \"../templates/\"\n",
    "outputs = \"../outputs/\"\n",
    "\n",
    "dotfile = \"graph_retweet.dot\"\n",
    "pngfile = \"graph_retweet.png\"\n",
    "protofile = \"graph_retweet.html\"\n",
    "tweetsfile = \"Tweets_dump.txt\"\n",
    "template_proto = 'template_protoviz.html'\n",
    "\n",
    "pathdotfile = os.path.join(outputs,dotfile)\n",
    "pathpngfile = os.path.join(outputs,pngfile)\n",
    "pathprotofile = os.path.join(outputs,protofile)\n",
    "pathtweetsfile = os.path.join(outputs,tweetsfile)\n",
    "pathtemplate = os.path.join(templates,template_proto)\n",
    "\n",
    "stoplist_en = nltk.corpus.stopwords.words('english')\n",
    "stoplist_pt = nltk.corpus.stopwords.words('portuguese')\n",
    "ignorewords = stoplist_en + stoplist_pt + ['',' ','-','rt']\n",
    "\n",
    "twitter_query = u'Earth'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using geographical resources within Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#https://pypi.python.org/pypi/geopy  \n",
    "\n",
    "gg.OpenMapQuest()\n",
    "geolocator = gg.GoogleV3()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To geolocate a query to an address and coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rua Dona Mariana - Botafogo, Rio de Janeiro - RJ, Brazil\n",
      "-22.9529422 -43.1886221\n"
     ]
    }
   ],
   "source": [
    "logradouro = \"Dona Mariana, Botafoga\" #Note that there is a typo in the name \"Botafogo\"\n",
    "address, (latitude, longitude) = geolocator.geocode(logradouro)\n",
    "print(address)\n",
    "print(latitude, longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8163265306122449"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Measuring editing distances between names:\n",
    "Levenshtein.ratio('Dona Mariana, Botafoga', 'Rua Dona Mariana - Botafogo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"800px\"\n",
       "            height=\"600px\"\n",
       "            src=\"http://maps.google.com/maps?q=Rua Dona Mariana - Botafogo, Rio de Janeiro - RJ, Brazil&loc:-22.9529422+-43.1886221&z=17&t=k&output=embed\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f4754c82a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#https://developers.google.com/maps/documentation/staticmaps/\n",
    "#http://stackoverflow.com/questions/2660201/what-parameters-should-i-use-in-a-google-maps-url-to-go-to-a-lat-lon/9919251#9919251\n",
    "#m – normal map k – satellite h – hybrid p – terrain\n",
    "\n",
    "def gmap(address,lat,lon,zoom=15,tmap='m'):\n",
    "    # Google Maps URL template for an iframe\n",
    "    google_maps_url = 'http://maps.google.com/maps?q={0}&loc:{1}+{2}&z={3}&t={4}&output=embed'.format(address,\n",
    "                                                                                                     lat,\n",
    "                                                                                                     lon,\n",
    "                                                                                                     zoom,\n",
    "                                                                                                     tmap,)\n",
    "    display(IFrame(google_maps_url, '800px', '600px'))\n",
    "    \n",
    "gmap(address, latitude, longitude,17,'k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the address corresponding to a set of coordinates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fauchy, 1148 Mont-la-Ville, Switzerland\n",
      "1148 Mont-la-Ville, Switzerland\n",
      "1148 Moiry, Switzerland\n",
      "Morges District, Switzerland\n",
      "Vaud, Switzerland\n",
      "Switzerland\n"
     ]
    }
   ],
   "source": [
    "addresses = geolocator.reverse(\"46.649,6.383\")\n",
    "for address in addresses:\n",
    "    print(address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Python and QGIS for geospatial visualizations - a Case Study  \n",
    "https://www.airpair.com/python/posts/using-python-and-qgis-for-geospatial-visualization  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "base_url = \"http://www.nuforc.org/webreports/\"\n",
    "index_url = \"http://www.nuforc.org/webreports/ndxevent.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def can_cast_as_dt(dateStr, fmt):\n",
    "    try:\n",
    "        datetime.strptime(dateStr, fmt)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "\n",
    "def parse_dt(dateStr):\n",
    "    # the data in the website comes in two different formats, try both \n",
    "    for fmt in [\"%m/%d/%y %H:%M\", \"%m/%d/%y\"]:\n",
    "        try:\n",
    "            return datetime.strptime(dateStr, fmt)\n",
    "        except ValueError:\n",
    "            continue\n",
    "\n",
    "def get_data_from_url(url):\n",
    "    print(\"Processing {}\".format(url))\n",
    "    data = []\n",
    "    source = BeautifulSoup(urllib.request.urlopen(url), \"html5lib\")\n",
    "    for row in source('tr'):\n",
    "        if not row('td'):\n",
    "            continue # header row\n",
    "        row_data = row('td')\n",
    "        # parse the datetime from the string\n",
    "        date_time = parse_dt(row_data[0].text)\n",
    "        city = row_data[1].text\n",
    "        state = row_data[2].text\n",
    "        shape = row_data[3].text\n",
    "        duration = row_data[4].text\n",
    "        data.append((date_time, city, state, shape, duration))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing http://www.nuforc.org/webreports/ndxe201609.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe201608.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe201607.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe201606.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe201605.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe201604.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe201603.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe201602.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe201601.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe201512.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe201511.html\n",
      "Processing http://www.nuforc.org/webreports/ndxe201510.html\n"
     ]
    }
   ],
   "source": [
    "# get the index page\n",
    "raw_page = urllib.request.urlopen(index_url)\n",
    "source = BeautifulSoup(raw_page, \"html5lib\")\n",
    "# get all the links in the index page\n",
    "func1 = lambda x: (x.text, base_url + x['href'])\n",
    "monthly_urls = list(map(func1,source('a')))\n",
    "# get  the last 12 links that have a text like 06/2015\n",
    "func2 = lambda x: can_cast_as_dt(x[0], \"%m/%Y\")\n",
    "last_year_urls = filter(func2, monthly_urls[0:13]) \n",
    "# extract the data from each monthly page and flatten the lists of tuples\n",
    "last_year_ufos = list(chain(*map(lambda x: get_data_from_url(x[1]), last_year_urls)))\n",
    "# initialize a pandas DataFrame with the list of tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ufos_df = pd.DataFrame(last_year_ufos, columns=[\"start\",\"city\",\"state\",\"shape\",\"duration_description\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-02 00:00:00</td>\n",
       "      <td>Greenfield</td>\n",
       "      <td>WI</td>\n",
       "      <td>Fireball</td>\n",
       "      <td>5 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-01 22:30:00</td>\n",
       "      <td>Brookfield</td>\n",
       "      <td>WI</td>\n",
       "      <td>Other</td>\n",
       "      <td>15 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-01 22:00:00</td>\n",
       "      <td>Lehighton</td>\n",
       "      <td>PA</td>\n",
       "      <td>Fireball</td>\n",
       "      <td>5 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-01 10:00:00</td>\n",
       "      <td>Dollar Bay</td>\n",
       "      <td>MI</td>\n",
       "      <td>Formation</td>\n",
       "      <td>2+ hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-01 05:29:00</td>\n",
       "      <td>Vale</td>\n",
       "      <td>NC</td>\n",
       "      <td>Light</td>\n",
       "      <td>2 seconds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                start        city state      shape duration_description\n",
       "0 2016-09-02 00:00:00  Greenfield    WI   Fireball            5 minutes\n",
       "1 2016-09-01 22:30:00  Brookfield    WI      Other           15 minutes\n",
       "2 2016-09-01 22:00:00   Lehighton    PA   Fireball            5 minutes\n",
       "3 2016-09-01 10:00:00  Dollar Bay    MI  Formation             2+ hours\n",
       "4 2016-09-01 05:29:00        Vale    NC      Light            2 seconds"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ufos_df.replace(to_replace='', value=np.nan, inplace=True, limit=None, regex=False, method='pad', axis=None)\n",
    "ufos_df = ufos_df.dropna() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-02 00:00:00</td>\n",
       "      <td>Greenfield</td>\n",
       "      <td>WI</td>\n",
       "      <td>Fireball</td>\n",
       "      <td>5 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-01 22:30:00</td>\n",
       "      <td>Brookfield</td>\n",
       "      <td>WI</td>\n",
       "      <td>Other</td>\n",
       "      <td>15 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-01 22:00:00</td>\n",
       "      <td>Lehighton</td>\n",
       "      <td>PA</td>\n",
       "      <td>Fireball</td>\n",
       "      <td>5 minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-01 10:00:00</td>\n",
       "      <td>Dollar Bay</td>\n",
       "      <td>MI</td>\n",
       "      <td>Formation</td>\n",
       "      <td>2+ hours</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-01 05:29:00</td>\n",
       "      <td>Vale</td>\n",
       "      <td>NC</td>\n",
       "      <td>Light</td>\n",
       "      <td>2 seconds</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                start        city state      shape duration_description\n",
       "0 2016-09-02 00:00:00  Greenfield    WI   Fireball            5 minutes\n",
       "1 2016-09-01 22:30:00  Brookfield    WI      Other           15 minutes\n",
       "2 2016-09-01 22:00:00   Lehighton    PA   Fireball            5 minutes\n",
       "3 2016-09-01 10:00:00  Dollar Bay    MI  Formation             2+ hours\n",
       "4 2016-09-01 05:29:00        Vale    NC      Light            2 seconds"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function that infers the duration from the text \n",
    "def infer_duration_in_seconds(text):\n",
    "    # try different regexps to extract the total seconds\n",
    "    text = text.replace('<','')\n",
    "    text = text.replace('>','')\n",
    "    text = text.replace('?','')\n",
    "    text = text.replace('+','')\n",
    "    text = text.replace('~','')\n",
    "    metric_text = [\"second\",\"s\",\"Second\",\"segundo\",\"minute\",\"m\",\"min\",\"Minute\",\"hour\",\"h\",\"Hour\",'Currently']\n",
    "    metric_seconds = [1,1,1,1,60,60,60,3600,3600,3600,10]\n",
    "    for metric,mult in zip(metric_text, metric_seconds):\n",
    "        regex = \"\\s*(\\d+)\\+?\\s*{}s?\".format(metric)\n",
    "        res = re.findall(regex,text)\n",
    "        if len(res)>0:\n",
    "            return int(float(res[0]) * mult)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# extract the duration in seconds\n",
    "ufos_df[\"duration_secs\"] = ufos_df[\"duration_description\"].apply(infer_duration_in_seconds)\n",
    "# now we can infer the end time of the UFO sighting as well\n",
    "# which will be useful for the animation later\n",
    "ufos_df[\"end\"] = ufos_df.apply(lambda x:x[\"start\"] + timedelta(seconds=x[\"duration_secs\"]),axis=1)\n",
    "ufos_df = ufos_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration_description</th>\n",
       "      <th>duration_secs</th>\n",
       "      <th>end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-02 00:00:00</td>\n",
       "      <td>Greenfield</td>\n",
       "      <td>WI</td>\n",
       "      <td>Fireball</td>\n",
       "      <td>5 minutes</td>\n",
       "      <td>300</td>\n",
       "      <td>2016-09-02 00:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-01 22:30:00</td>\n",
       "      <td>Brookfield</td>\n",
       "      <td>WI</td>\n",
       "      <td>Other</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>900</td>\n",
       "      <td>2016-09-01 22:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-01 22:00:00</td>\n",
       "      <td>Lehighton</td>\n",
       "      <td>PA</td>\n",
       "      <td>Fireball</td>\n",
       "      <td>5 minutes</td>\n",
       "      <td>300</td>\n",
       "      <td>2016-09-01 22:05:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-01 10:00:00</td>\n",
       "      <td>Dollar Bay</td>\n",
       "      <td>MI</td>\n",
       "      <td>Formation</td>\n",
       "      <td>2+ hours</td>\n",
       "      <td>7200</td>\n",
       "      <td>2016-09-01 12:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-01 05:29:00</td>\n",
       "      <td>Vale</td>\n",
       "      <td>NC</td>\n",
       "      <td>Light</td>\n",
       "      <td>2 seconds</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-09-01 05:29:02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                start        city state      shape duration_description  \\\n",
       "0 2016-09-02 00:00:00  Greenfield    WI   Fireball            5 minutes   \n",
       "1 2016-09-01 22:30:00  Brookfield    WI      Other           15 minutes   \n",
       "2 2016-09-01 22:00:00   Lehighton    PA   Fireball            5 minutes   \n",
       "3 2016-09-01 10:00:00  Dollar Bay    MI  Formation             2+ hours   \n",
       "4 2016-09-01 05:29:00        Vale    NC      Light            2 seconds   \n",
       "\n",
       "   duration_secs                 end  \n",
       "0            300 2016-09-02 00:05:00  \n",
       "1            900 2016-09-01 22:45:00  \n",
       "2            300 2016-09-01 22:05:00  \n",
       "3           7200 2016-09-01 12:00:00  \n",
       "4              2 2016-09-01 05:29:02  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ufos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'boundingbox': ['36.930691', '37.2206658', '-76.6460929', '-76.3616099'],\n",
       "  'class': 'place',\n",
       "  'display_name': 'Newport News, Newport News City, Virginia, United States of America',\n",
       "  'icon': 'http://nominatim.openstreetmap.org/images/mapicons/poi_place_city.p.20.png',\n",
       "  'importance': 0.70997691224355,\n",
       "  'lat': '37.016827',\n",
       "  'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. http://www.openstreetmap.org/copyright',\n",
       "  'lon': '-76.4505195',\n",
       "  'osm_id': '206655',\n",
       "  'osm_type': 'relation',\n",
       "  'place_id': '144553196',\n",
       "  'type': 'city'},\n",
       " {'boundingbox': ['37.0728977', '37.0731352', '-76.478543', '-76.478097'],\n",
       "  'class': 'amenity',\n",
       "  'display_name': 'Station 8, Kingstowne Drive, Deer Park, Newport News, Newport News City, Virginia, 23606, United States of America',\n",
       "  'icon': 'http://nominatim.openstreetmap.org/images/mapicons/amenity_firestation3.p.20.png',\n",
       "  'importance': 0.201,\n",
       "  'lat': '37.0730099',\n",
       "  'licence': 'Data © OpenStreetMap contributors, ODbL 1.0. http://www.openstreetmap.org/copyright',\n",
       "  'lon': '-76.4783236633768',\n",
       "  'osm_id': '248256123',\n",
       "  'osm_type': 'way',\n",
       "  'place_id': '120984000',\n",
       "  'type': 'fire_station'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://wiki.openstreetmap.org/wiki/Nominatim_usage_policy\n",
    "# https://github.com/twain47/Nominatim/blob/master/docs/Installation.md\n",
    "geolocator = Nominatim()\n",
    "\n",
    "geolocator.query('Newport News')\n",
    "#geolocator.query(\"Houston, TX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rsouza/python/3/venv/local/lib/python3.5/site-packages/ipykernel/__main__.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/home/rsouza/python/3/venv/local/lib/python3.5/site-packages/pandas/core/indexing.py:132: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n",
      "/home/rsouza/python/3/venv/local/lib/python3.5/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "ufos_df[\"lat\"] = 0\n",
    "ufos_df[\"lon\"] = 0\n",
    "for i in range(len(ufos_df[0:20])):\n",
    "    resp_json = geolocator.query(ufos_df['city'][i])\n",
    "    try:\n",
    "        ufos_df[\"lat\"][i] = resp_json[0]['lat']\n",
    "        ufos_df[\"lon\"][i] = resp_json[0]['lon']\n",
    "    except:\n",
    "        ufos_df[\"lat\"][i] = 0\n",
    "        ufos_df[\"lat\"][i] = 0\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>shape</th>\n",
       "      <th>duration_description</th>\n",
       "      <th>duration_secs</th>\n",
       "      <th>end</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-09-02 00:00:00</td>\n",
       "      <td>Greenfield</td>\n",
       "      <td>WI</td>\n",
       "      <td>Fireball</td>\n",
       "      <td>5 minutes</td>\n",
       "      <td>300</td>\n",
       "      <td>2016-09-02 00:05:00</td>\n",
       "      <td>42.5877962</td>\n",
       "      <td>-72.6006198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-09-01 22:30:00</td>\n",
       "      <td>Brookfield</td>\n",
       "      <td>WI</td>\n",
       "      <td>Other</td>\n",
       "      <td>15 minutes</td>\n",
       "      <td>900</td>\n",
       "      <td>2016-09-01 22:45:00</td>\n",
       "      <td>43.0605671</td>\n",
       "      <td>-88.1064786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-09-01 22:00:00</td>\n",
       "      <td>Lehighton</td>\n",
       "      <td>PA</td>\n",
       "      <td>Fireball</td>\n",
       "      <td>5 minutes</td>\n",
       "      <td>300</td>\n",
       "      <td>2016-09-01 22:05:00</td>\n",
       "      <td>40.8337029</td>\n",
       "      <td>-75.7138007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-09-01 10:00:00</td>\n",
       "      <td>Dollar Bay</td>\n",
       "      <td>MI</td>\n",
       "      <td>Formation</td>\n",
       "      <td>2+ hours</td>\n",
       "      <td>7200</td>\n",
       "      <td>2016-09-01 12:00:00</td>\n",
       "      <td>47.1196494</td>\n",
       "      <td>-88.5115108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-09-01 05:29:00</td>\n",
       "      <td>Vale</td>\n",
       "      <td>NC</td>\n",
       "      <td>Light</td>\n",
       "      <td>2 seconds</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-09-01 05:29:02</td>\n",
       "      <td>13.2904027</td>\n",
       "      <td>108.4265113</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                start        city state      shape duration_description  \\\n",
       "0 2016-09-02 00:00:00  Greenfield    WI   Fireball            5 minutes   \n",
       "1 2016-09-01 22:30:00  Brookfield    WI      Other           15 minutes   \n",
       "2 2016-09-01 22:00:00   Lehighton    PA   Fireball            5 minutes   \n",
       "3 2016-09-01 10:00:00  Dollar Bay    MI  Formation             2+ hours   \n",
       "4 2016-09-01 05:29:00        Vale    NC      Light            2 seconds   \n",
       "\n",
       "   duration_secs                 end         lat          lon  \n",
       "0            300 2016-09-02 00:05:00  42.5877962  -72.6006198  \n",
       "1            900 2016-09-01 22:45:00  43.0605671  -88.1064786  \n",
       "2            300 2016-09-01 22:05:00  40.8337029  -75.7138007  \n",
       "3           7200 2016-09-01 12:00:00  47.1196494  -88.5115108  \n",
       "4              2 2016-09-01 05:29:02  13.2904027  108.4265113  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# http://stackoverflow.com/questions/17098654/how-to-store-data-frame-using-pandas-python\n",
    "ufos_df.to_pickle(os.path.join(outputs,'ufos_df.pkl'))\n",
    "ufos_df = pd.read_pickle(os.path.join(outputs,'ufos_df.pkl'))\n",
    "ufos_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Note: dropna will drop any columns with None values, which is desirable\n",
    "ufos_df[[\"start\",\"end\",\"lon\",\"lat\",\"shape\"]].dropna().to_csv(os.path.join(outputs,'ufo_data.csv'),\n",
    "                                                             index=False, \n",
    "                                                             encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using geographical resources for twitter Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/bear/python-twitter (before was http://code.google.com/p/python-twitter/)  \n",
    "https://dev.twitter.com/docs  \n",
    "\n",
    "Twitter API Keys  \n",
    "Please generate yours...  \n",
    "Go to http://twitter.com/apps/new to create an app and get these items  \n",
    "See https://dev.twitter.com/docs/auth/oauth for more information on Twitter's OAuth implementation  \n",
    "https://dev.twitter.com/rest/reference/get/account/verify_credentials  \n",
    "https://dev.twitter.com/docs/auth/oauth  \n",
    "https://dev.twitter.com/apps/new  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('twitter_tokens.txt', 'r') as twitter_tokens:\n",
    "    tokens = twitter_tokens.read().split(',')\n",
    "consumer_key = tokens[0].strip()\n",
    "consumer_secret = tokens[1].strip()\n",
    "access_token = tokens[2].strip()\n",
    "access_token_secret = tokens[3].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acessing Twitter (with or without authentication)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#api = twitter.Api() # Accessing with no authentication\n",
    "api = twitter.Api(consumer_key, consumer_secret, access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"created_at\": \"Thu Apr 09 10:44:07 +0000 2009\", \"description\": \"Researcher and Professor\", \"favourites_count\": 1, \"followers_count\": 494, \"friends_count\": 133, \"id\": 29959702, \"lang\": \"en\", \"listed_count\": 19, \"location\": \"Rio de Janeiro\", \"name\": \"Renato Rocha Souza\", \"profile_background_color\": \"9AE4E8\", \"profile_background_image_url\": \"http://pbs.twimg.com/profile_background_images/33941499/8.jpg\", \"profile_image_url\": \"http://pbs.twimg.com/profile_images/503088023/Renato2_normal.JPG\", \"profile_link_color\": \"0084B4\", \"profile_sidebar_fill_color\": \"DDFFCC\", \"profile_text_color\": \"333333\", \"screen_name\": \"rrsouza\", \"status\": {\"created_at\": \"Mon Jan 05 11:05:11 +0000 2015\", \"hashtags\": [{\"text\": \"FGV\"}, {\"text\": \"emap\"}], \"id\": 552058220781797376, \"id_str\": \"552058220781797376\", \"lang\": \"und\", \"source\": \"<a href=\\\"http://twitter.com\\\" rel=\\\"nofollow\\\">Twitter Web Client</a>\", \"text\": \"http://t.co/5l4lGVKiBG #FGV #emap\", \"urls\": [{\"expanded_url\": \"http://blog.udacity.com/2014/11/data-science-job-skills.html?utm_source=sendgrid&utm_medium=email&utm_campaign=nyr-ps-2\", \"url\": \"http://t.co/5l4lGVKiBG\"}], \"user_mentions\": []}, \"statuses_count\": 1365, \"time_zone\": \"London\", \"url\": \"http://t.co/Bw5u7mg5\", \"utc_offset\": 3600}\n"
     ]
    }
   ],
   "source": [
    "print(api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lexical Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent (random) public messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "msgpublicas = api.GetStreamSample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "決戦！暴走チョッパー\n",
      "★9/5(12:00)〜9/6(11:59)期間限定★\n",
      "難易度マスタークリアで手配書入手確定！\n",
      "https://t.co/rPJfCxrYFN　#トレクル https://t.co/z1jBX7pv8M\n",
      "\n",
      "RT @MalaliBashir: Heavy explosion rocked Kabul twenty minutes ago. No information on dead and wounded yet. #Kabulblast\n",
      "\n",
      "wow i am rly gay\n",
      "\n",
      "Don't worry about me 😂 tf\n",
      "\n",
      "nefret benim kimliğim bana gücümü sağlıyo ve kibrimi\n",
      "\n",
      "RT @ambitiousniecey: You CAN NOT trip over someone who isn't even yours .\n",
      "\n",
      "Come see me naked on cam ► Got to my profile and click the website! I swear it will be fun! #nsfw #porn #sexting #baldpussy\n",
      "\n",
      "فلم سكس - ممحونة بالمكتب..https://t.co/O7HxyzLFu6  https://t.co/HstY0AJ8A9 98w\n",
      "زب\n",
      "طيز\n",
      "فيديو_سكس\n",
      "3325\n",
      "\n",
      "@NomzamoMbatha wena noSbu, that last scene. #Ubuchwepheshe\n",
      "\n",
      "أضفت فيديو إلى قائمة تشغيل @YouTube على https://t.co/yOhLl7DX64 حل مشكلة دخول السيرفرات\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    tweet = next(msgpublicas)\n",
    "    if 'text' in tweet:\n",
    "        print(u'{}\\n'.format(tweet['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tweet Structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'contributors': None,\n",
       " 'coordinates': None,\n",
       " 'created_at': 'Mon Sep 05 19:03:14 +0000 2016',\n",
       " 'entities': {'hashtags': [],\n",
       "  'media': [{'display_url': 'pic.twitter.com/yxUr55pM5G',\n",
       "    'expanded_url': 'http://twitter.com/Nero_AzC/status/762358124732882946/photo/1',\n",
       "    'id': 762357852044492805,\n",
       "    'id_str': '762357852044492805',\n",
       "    'indices': [60, 83],\n",
       "    'media_url': 'http://pbs.twimg.com/media/CpRwbWLXgAUSadm.jpg',\n",
       "    'media_url_https': 'https://pbs.twimg.com/media/CpRwbWLXgAUSadm.jpg',\n",
       "    'sizes': {'large': {'h': 264, 'resize': 'fit', 'w': 592},\n",
       "     'medium': {'h': 264, 'resize': 'fit', 'w': 592},\n",
       "     'small': {'h': 264, 'resize': 'fit', 'w': 592},\n",
       "     'thumb': {'h': 150, 'resize': 'crop', 'w': 150}},\n",
       "    'source_status_id': 762358124732882946,\n",
       "    'source_status_id_str': '762358124732882946',\n",
       "    'source_user_id': 3090843159,\n",
       "    'source_user_id_str': '3090843159',\n",
       "    'type': 'photo',\n",
       "    'url': 'https://t.co/yxUr55pM5G'}],\n",
       "  'symbols': [],\n",
       "  'urls': [],\n",
       "  'user_mentions': [{'id': 3090843159,\n",
       "    'id_str': '3090843159',\n",
       "    'indices': [3, 12],\n",
       "    'name': 'Иeʀo ♛',\n",
       "    'screen_name': 'Nero_AzC'},\n",
       "   {'id': 4113487139,\n",
       "    'id_str': '4113487139',\n",
       "    'indices': [55, 59],\n",
       "    'name': 'Jul',\n",
       "    'screen_name': 'jul'}]},\n",
       " 'extended_entities': {'media': [{'display_url': 'pic.twitter.com/yxUr55pM5G',\n",
       "    'expanded_url': 'http://twitter.com/Nero_AzC/status/762358124732882946/photo/1',\n",
       "    'id': 762357852044492805,\n",
       "    'id_str': '762357852044492805',\n",
       "    'indices': [60, 83],\n",
       "    'media_url': 'http://pbs.twimg.com/media/CpRwbWLXgAUSadm.jpg',\n",
       "    'media_url_https': 'https://pbs.twimg.com/media/CpRwbWLXgAUSadm.jpg',\n",
       "    'sizes': {'large': {'h': 264, 'resize': 'fit', 'w': 592},\n",
       "     'medium': {'h': 264, 'resize': 'fit', 'w': 592},\n",
       "     'small': {'h': 264, 'resize': 'fit', 'w': 592},\n",
       "     'thumb': {'h': 150, 'resize': 'crop', 'w': 150}},\n",
       "    'source_status_id': 762358124732882946,\n",
       "    'source_status_id_str': '762358124732882946',\n",
       "    'source_user_id': 3090843159,\n",
       "    'source_user_id_str': '3090843159',\n",
       "    'type': 'photo',\n",
       "    'url': 'https://t.co/yxUr55pM5G'},\n",
       "   {'display_url': 'pic.twitter.com/yxUr55pM5G',\n",
       "    'expanded_url': 'http://twitter.com/Nero_AzC/status/762358124732882946/photo/1',\n",
       "    'id': 762357867009732608,\n",
       "    'id_str': '762357867009732608',\n",
       "    'indices': [60, 83],\n",
       "    'media_url': 'http://pbs.twimg.com/media/CpRwcN7W8AAMjy_.jpg',\n",
       "    'media_url_https': 'https://pbs.twimg.com/media/CpRwcN7W8AAMjy_.jpg',\n",
       "    'sizes': {'large': {'h': 212, 'resize': 'fit', 'w': 476},\n",
       "     'medium': {'h': 212, 'resize': 'fit', 'w': 476},\n",
       "     'small': {'h': 212, 'resize': 'fit', 'w': 476},\n",
       "     'thumb': {'h': 150, 'resize': 'crop', 'w': 150}},\n",
       "    'source_status_id': 762358124732882946,\n",
       "    'source_status_id_str': '762358124732882946',\n",
       "    'source_user_id': 3090843159,\n",
       "    'source_user_id_str': '3090843159',\n",
       "    'type': 'photo',\n",
       "    'url': 'https://t.co/yxUr55pM5G'}]},\n",
       " 'favorite_count': 0,\n",
       " 'favorited': False,\n",
       " 'filter_level': 'low',\n",
       " 'geo': None,\n",
       " 'id': 772872737949966336,\n",
       " 'id_str': '772872737949966336',\n",
       " 'in_reply_to_screen_name': None,\n",
       " 'in_reply_to_status_id': None,\n",
       " 'in_reply_to_status_id_str': None,\n",
       " 'in_reply_to_user_id': None,\n",
       " 'in_reply_to_user_id_str': None,\n",
       " 'is_quote_status': False,\n",
       " 'lang': 'fr',\n",
       " 'place': None,\n",
       " 'possibly_sensitive': False,\n",
       " 'retweet_count': 0,\n",
       " 'retweeted': False,\n",
       " 'retweeted_status': {'contributors': None,\n",
       "  'coordinates': None,\n",
       "  'created_at': 'Sun Aug 07 18:41:55 +0000 2016',\n",
       "  'entities': {'hashtags': [],\n",
       "   'media': [{'display_url': 'pic.twitter.com/yxUr55pM5G',\n",
       "     'expanded_url': 'http://twitter.com/Nero_AzC/status/762358124732882946/photo/1',\n",
       "     'id': 762357852044492805,\n",
       "     'id_str': '762357852044492805',\n",
       "     'indices': [46, 69],\n",
       "     'media_url': 'http://pbs.twimg.com/media/CpRwbWLXgAUSadm.jpg',\n",
       "     'media_url_https': 'https://pbs.twimg.com/media/CpRwbWLXgAUSadm.jpg',\n",
       "     'sizes': {'large': {'h': 264, 'resize': 'fit', 'w': 592},\n",
       "      'medium': {'h': 264, 'resize': 'fit', 'w': 592},\n",
       "      'small': {'h': 264, 'resize': 'fit', 'w': 592},\n",
       "      'thumb': {'h': 150, 'resize': 'crop', 'w': 150}},\n",
       "     'type': 'photo',\n",
       "     'url': 'https://t.co/yxUr55pM5G'}],\n",
       "   'symbols': [],\n",
       "   'urls': [],\n",
       "   'user_mentions': [{'id': 4113487139,\n",
       "     'id_str': '4113487139',\n",
       "     'indices': [41, 45],\n",
       "     'name': 'Jul',\n",
       "     'screen_name': 'jul'}]},\n",
       "  'extended_entities': {'media': [{'display_url': 'pic.twitter.com/yxUr55pM5G',\n",
       "     'expanded_url': 'http://twitter.com/Nero_AzC/status/762358124732882946/photo/1',\n",
       "     'id': 762357852044492805,\n",
       "     'id_str': '762357852044492805',\n",
       "     'indices': [46, 69],\n",
       "     'media_url': 'http://pbs.twimg.com/media/CpRwbWLXgAUSadm.jpg',\n",
       "     'media_url_https': 'https://pbs.twimg.com/media/CpRwbWLXgAUSadm.jpg',\n",
       "     'sizes': {'large': {'h': 264, 'resize': 'fit', 'w': 592},\n",
       "      'medium': {'h': 264, 'resize': 'fit', 'w': 592},\n",
       "      'small': {'h': 264, 'resize': 'fit', 'w': 592},\n",
       "      'thumb': {'h': 150, 'resize': 'crop', 'w': 150}},\n",
       "     'type': 'photo',\n",
       "     'url': 'https://t.co/yxUr55pM5G'},\n",
       "    {'display_url': 'pic.twitter.com/yxUr55pM5G',\n",
       "     'expanded_url': 'http://twitter.com/Nero_AzC/status/762358124732882946/photo/1',\n",
       "     'id': 762357867009732608,\n",
       "     'id_str': '762357867009732608',\n",
       "     'indices': [46, 69],\n",
       "     'media_url': 'http://pbs.twimg.com/media/CpRwcN7W8AAMjy_.jpg',\n",
       "     'media_url_https': 'https://pbs.twimg.com/media/CpRwcN7W8AAMjy_.jpg',\n",
       "     'sizes': {'large': {'h': 212, 'resize': 'fit', 'w': 476},\n",
       "      'medium': {'h': 212, 'resize': 'fit', 'w': 476},\n",
       "      'small': {'h': 212, 'resize': 'fit', 'w': 476},\n",
       "      'thumb': {'h': 150, 'resize': 'crop', 'w': 150}},\n",
       "     'type': 'photo',\n",
       "     'url': 'https://t.co/yxUr55pM5G'}]},\n",
       "  'favorite_count': 1599,\n",
       "  'favorited': False,\n",
       "  'filter_level': 'low',\n",
       "  'geo': None,\n",
       "  'id': 762358124732882946,\n",
       "  'id_str': '762358124732882946',\n",
       "  'in_reply_to_screen_name': None,\n",
       "  'in_reply_to_status_id': None,\n",
       "  'in_reply_to_status_id_str': None,\n",
       "  'in_reply_to_user_id': None,\n",
       "  'in_reply_to_user_id_str': None,\n",
       "  'is_quote_status': False,\n",
       "  'lang': 'fr',\n",
       "  'place': None,\n",
       "  'possibly_sensitive': True,\n",
       "  'retweet_count': 4455,\n",
       "  'retweeted': False,\n",
       "  'source': '<a href=\"http://twitter.com\" rel=\"nofollow\">Twitter Web Client</a>',\n",
       "  'text': 'Les hommes mentent mais pas les chiffres @jul https://t.co/yxUr55pM5G',\n",
       "  'truncated': False,\n",
       "  'user': {'contributors_enabled': False,\n",
       "   'created_at': 'Fri Mar 13 08:34:24 +0000 2015',\n",
       "   'default_profile': False,\n",
       "   'default_profile_image': False,\n",
       "   'description': \"Jeune psy très effronté | me mentionne pas j'men bat les couilles twitter c virtuel qd jverouille mon tel vs existez pu | tchek mes fav\",\n",
       "   'favourites_count': 330,\n",
       "   'follow_request_sent': None,\n",
       "   'followers_count': 43641,\n",
       "   'following': None,\n",
       "   'friends_count': 9,\n",
       "   'geo_enabled': False,\n",
       "   'id': 3090843159,\n",
       "   'id_str': '3090843159',\n",
       "   'is_translator': False,\n",
       "   'lang': 'fr',\n",
       "   'listed_count': 63,\n",
       "   'location': 'Rave on ॐ | 1.618 | φ',\n",
       "   'name': 'Иeʀo ♛',\n",
       "   'notifications': None,\n",
       "   'profile_background_color': '000000',\n",
       "   'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "   'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
       "   'profile_background_tile': False,\n",
       "   'profile_banner_url': 'https://pbs.twimg.com/profile_banners/3090843159/1468826045',\n",
       "   'profile_image_url': 'http://pbs.twimg.com/profile_images/685419941831507968/BpI5quOl_normal.jpg',\n",
       "   'profile_image_url_https': 'https://pbs.twimg.com/profile_images/685419941831507968/BpI5quOl_normal.jpg',\n",
       "   'profile_link_color': '1B95E0',\n",
       "   'profile_sidebar_border_color': '000000',\n",
       "   'profile_sidebar_fill_color': '000000',\n",
       "   'profile_text_color': '000000',\n",
       "   'profile_use_background_image': False,\n",
       "   'protected': False,\n",
       "   'screen_name': 'Nero_AzC',\n",
       "   'statuses_count': 3453,\n",
       "   'time_zone': 'Pacific Time (US & Canada)',\n",
       "   'url': 'http://instagram.com/Nero_AzC',\n",
       "   'utc_offset': -25200,\n",
       "   'verified': False}},\n",
       " 'source': '<a href=\"http://twitter.com/download/iphone\" rel=\"nofollow\">Twitter for iPhone</a>',\n",
       " 'text': 'RT @Nero_AzC: Les hommes mentent mais pas les chiffres @jul https://t.co/yxUr55pM5G',\n",
       " 'timestamp_ms': '1473102194665',\n",
       " 'truncated': False,\n",
       " 'user': {'contributors_enabled': False,\n",
       "  'created_at': 'Sun Jul 21 11:56:11 +0000 2013',\n",
       "  'default_profile': False,\n",
       "  'default_profile_image': False,\n",
       "  'description': 'IG : Lauraaa_dly #TeamOM ⚪️Ⓜ️',\n",
       "  'favourites_count': 4823,\n",
       "  'follow_request_sent': None,\n",
       "  'followers_count': 516,\n",
       "  'following': None,\n",
       "  'friends_count': 319,\n",
       "  'geo_enabled': False,\n",
       "  'id': 1610351190,\n",
       "  'id_str': '1610351190',\n",
       "  'is_translator': False,\n",
       "  'lang': 'fr',\n",
       "  'listed_count': 8,\n",
       "  'location': 'Bretagne, France',\n",
       "  'name': '.ناتان',\n",
       "  'notifications': None,\n",
       "  'profile_background_color': 'ACDED6',\n",
       "  'profile_background_image_url': 'http://pbs.twimg.com/profile_background_images/437324908809314304/SV2NWd8x.jpeg',\n",
       "  'profile_background_image_url_https': 'https://pbs.twimg.com/profile_background_images/437324908809314304/SV2NWd8x.jpeg',\n",
       "  'profile_background_tile': True,\n",
       "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1610351190/1469996345',\n",
       "  'profile_image_url': 'http://pbs.twimg.com/profile_images/769934197217751040/gxDmLIZA_normal.jpg',\n",
       "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/769934197217751040/gxDmLIZA_normal.jpg',\n",
       "  'profile_link_color': '00FFB7',\n",
       "  'profile_sidebar_border_color': 'FFFFFF',\n",
       "  'profile_sidebar_fill_color': 'DDEEF6',\n",
       "  'profile_text_color': '333333',\n",
       "  'profile_use_background_image': True,\n",
       "  'protected': False,\n",
       "  'screen_name': 'Laura_Dly',\n",
       "  'statuses_count': 20376,\n",
       "  'time_zone': 'Paris',\n",
       "  'url': None,\n",
       "  'utc_offset': 7200,\n",
       "  'verified': False}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "while True:\n",
    "    tweet = next(msgpublicas)\n",
    "    if 'user' in tweet:\n",
    "        break\n",
    "tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://mike.teczno.com/img/raffi-krikorian-map-of-a-tweet.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url='http://mike.teczno.com/img/raffi-krikorian-map-of-a-tweet.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent messages from an user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RT @Nero_AzC: Les hommes mentent mais pas les chiffres @jul https://t.co/yxUr55pM5G', \"Le problème avec certaines personnes c'est qu'elles respirent 👋🏻\", '@ChaarlotteDLM Non mais il se rend pas compte comment il peut être blessant ! Te prends pas la tête avec ce connard sérieux.', 'RT @Team_Poissons: Le #Poisson est vraiment très possessif.', 'RT @Cava2minutes: Combien te déteste mais te surveille 👀', '\"Sa pute\" elle t\\'emmerde! Ok connard?', 'Hâte de retrouver #TPMP 👍🏻 \\n#TPMPIsBack', \"J'ai passé une commande chez @mrwonderful_fr 😍\", \"RT @wwwxdatsme_: Moi j'aime trop quand je suis amoureuse d'un garçon. Et lui il me prend pour une conne.\", '@ChaarlotteDLM mdr', \"RT @Ameliembkmbi_: 43 - T'écoute Jul t'es disqualifier ⛔️ ⛔️\", '@ChaarlotteDLM ouiii', 'RT @ChaarlotteDLM: Je suis en vacances je vais peut être en profiter pour appeler @Laura_Dly en FaceTime', 'Ça fait 4 nuit que je fais des insomnies 😴', \"RT @Team_Poissons: Le #Poisson s'épuise à trop penser, à trop analyser.\", 'RT @LeVraiHoroscope: Le #Poissons est plus enclin à suivre ses croyances ou ses sentiments que les faits et la logique.', \"@MatthieuGignac et ça, ça a 24 ans et Ben c'est triste 😐\", '@MatthieuGignac tu crois trop que le monde tourne autour de toi redescend 😊', \"@MatthieuGignac c'est à toi de bouger 😊😊😊\", '@MatthieuGignac avec un autre gars en même temps']\n"
     ]
    }
   ],
   "source": [
    "msguser = api.GetUserTimeline(tweet['user']['id'])\n",
    "print([s.text for s in msguser])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recent messages from the authenticated user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['http://t.co/5l4lGVKiBG #FGV #emap', 'Olá Pessoal! Fiquem atentos à aula de Modelagem e Mineração de Dados... Hoje análises com Twitter!', 'Mais um curioso fenômeno dos nossos tempos: #LeakForJLaw Or maybe #LeakForPerverts ?', 'RT @mashable: 8 Brutally Honest Facebook Notifications That Need to Exist Now http://t.co/wwFQ1hut9x http://t.co/b2GjxcNb6D', '#Cite10CoisasQueSuaMãeFala come alguma coisa antes para não chegar na festa esfomeado', 'Implicações do Big Data para as questões de privacidade: http://t.co/WDJwxpOr9d', 'Resultados da seleção do Mestrado em Modelagem Matemática da Informação - turma 2013 saem nesta sexta, 08/02. #FGV #EMAp', 'RT @PyPLN: We just released the very first version (0.1.0) of pypln.api -- a Python library to programatically access @PyPLN Web! http:/ ...', \"Men's Fitness UK by Dennis Publishing Ltd http://t.co/y8YZBBeP\", \"I'm at Capes (Brasília, DF) w/ 2 others http://t.co/QiukVJqW\", \"I'm at Capes (Brasília, DF) http://t.co/OfRoPS0y\", '@israelst na verdade, as que SABEM lidar com informacoes incompletas...', \"I'm at Grotemarkt http://t.co/Ber45XPB\", \"I'm at ULB - Research Department Technology Transfer Office http://t.co/DA9S0o7Q\", 'RT @RicardoRBarbosa: Coming Next: Doctors Prescribing Apps to Patients http://t.co/RhhUyOf4', 'RT @LinuxForYou: Microsoft Was Forced To Go The Open Source Way In Office 2013! http://t.co/jXblYN8l', '@joyfigueiro chique! Que bom...', '@joyfigueiro só no Brasil... Veja: http://t.co/jApke03n bis.', 'Sir Paul McCartney dando seu toque especial na abertura das olimpiadas...', 'Perdi o Sonnen para ver o Sonnen perder... #GoSpider']\n"
     ]
    }
   ],
   "source": [
    "msguser = api.GetUserTimeline('rrsouza')\n",
    "#msguser = api.GetUserTimeline('29959702')\n",
    "print([s.text for s in msguser])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After authentication, more options are available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lucas Parisi', 'Carla Codeço Coelho', 'Overleaf', 'Cláudio Berrondo', 'Flávio Amieiro', 'Pablo Cerdeira', 'Cut the Rope', 'Machinalis', 'MiningTheSocialWeb', 'CNET News', 'ReadWrite', 'The Next Web 🌍💻📱', 'CNET', 'The Verge', 'Engadget', 'Lifehacker', 'Gizmodo', 'WIRED', 'TechCrunch', 'Ian Ozsvald', 'CNPq', 'Claudio Gnoli', 'strongsteam', 'Diana Maynard', 'Joyce Figueiró', 'Álvaro Justen', 'PyPLN', 'Open Source For You', 'TechRepublic', 'ZDNet', 'Twitter API', 'Udacity', 'Clarissa', 'Roberto R.S.Sobrinho', 'Luana Sales', 'Sensacionalista', 'André Branco', 'CMA', 'Asla Sá', 'Renata Teixeira', 'FGV EMAp', 'FGV', 'FGV Marketing', 'CPDOC', 'Globant Brasil', 'Sheffield NLP', 'Débora Pereira', 'André Andrade', \"O'Reilly Radar\", 'Virgilio Almeida', 'Dalai Lama', 'Alexandre Colucci', 'Benildes Maculan', 'Gabriel Rezende', 'Mashable', 'alfredo hirsch', 'Fernando S Parreiras', 'NYTimes Bits', 'MiniCursos', 'Googleverse', 'Hootsuite', 'G1 - Concursos', 'Ivana', 'Dina Araujo', 'João Batista', 'W3C Brasil', 'ASIS&T', 'PPCGI UFPB', 'Ursula Blattmann', 'Google', 'Maria Inês Tomaél', 'Nanci Oddone', 'Pierre Levy', 'PPGCI - Unesp', 'Silvana G. Vidotti', 'John C. Dvorak', 'Rob Enderle', 'Leon F. Seltzer', 'Word Spy', 'TIME.com', 'CNN Breaking News', 'Guardian Data', 'Ciência Hoje', 'Carlos A Figueiredo', 'New Scientist', 'Wagner Meira Jr', 'Nathan Yau', 'Marcelo Martins', 'Kalina Bontcheva', 'Ana Souza', 'Instituto Novo Ser', \"Tim O'Reilly\", 'Guardian Tech', 'WebHolic!', 'Projeto TrackSource', 'DEF CON', 'Chronic Developments', 'Grupo ReCOL', 'Finep', 'Ricardo Caspirro', 't3', 'michelle Bouhid', 'Wefollow', 'Leonardo Souza', 'Luiz Maia', 'Aldo de A. Barreto', 'Adriana Bogliolo', 'TheFreeDictionary', 'Niraj Aswani', 'hamish cunningham', 'Stasa Vujicic', 'Guilherme A. Dias', 'AGNALDO', 'Camila', 'Joana Ziller', 'Saldanha', 'Hagar Espanha Gomes', 'Mozart Lima', 'Elaine Mosconi', 'Renata Vieira', 'Howard Rheingold', 'Eduardo Chaves', 'Carlos Nepomuceno', 'GATE (gate.ac.uk)', 'Jaime Bastos', 'GO Outdoors Official', 'Joyce Prado', 'marcellobax', 'Rivadávia C.D.A.Neto', 'Helio', 'Maria Manuel Borges', 'Flávio Codeço Coelho', 'RicardoRBarbosa']\n"
     ]
    }
   ],
   "source": [
    "userfollow = api.GetFriends()\n",
    "print([u.name for u in userfollow])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lexical_diversity(text):\n",
    "    return len(text) / len(set(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for a term in tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def search_for_term(termo, pages, results):\n",
    "    '''Search and return tweets on a subject (5 pages of 100 results each)\n",
    "    Save results in a file defined in \"pathtweetsfile\" '''\n",
    "    search_results = []\n",
    "    tweets = []\n",
    "    tweets_txt = []\n",
    "    tweets_words = []\n",
    "    names = []\n",
    "    last = api.GetSearch(term=termo, count=1)\n",
    "    search_results.append(last)\n",
    "    list_ids = []\n",
    "    list_ids.append(last[0].GetId())\n",
    "    for i in range(pages):\n",
    "        id_last = last[0].GetId()\n",
    "        new_tweets = api.GetSearch(term=termo, count=results, max_id=min(list_ids))\n",
    "        for i in range(len(new_tweets)):\n",
    "            list_ids.append(new_tweets[i].GetId())\n",
    "        search_results.append(new_tweets)\n",
    "    for i in range(len(search_results)):\n",
    "        for j in range(len(search_results[i])):\n",
    "            tweets.append(search_results[i][j])\n",
    "    tweets_txt += [tweet.text.split(u' ') for tweet in tweets]\n",
    "    for i in range(len(tweets)):\n",
    "        tweets_words += [word.lower().strip(u':@&$!?') for word in tweets_txt[i]]\n",
    "    for i in range(len(tweets)): \n",
    "        names += [word.strip(u':@&$!?') for word in tweets_txt[i] if word.istitle() and len(word) > 2]\n",
    "    out = file(pathtweetsfile,'w')\n",
    "    for tweet in tweets_txt: \n",
    "        out.write(u'\\n{}'.format(tweet))\n",
    "    return tweets, tweets_txt, tweets_words, names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last = api.GetSearch(term='Dilma', count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Status(ID=772598066855743488, ScreenName=folha, Created=Mon Sep 05 00:51:47 +0000 2016, Text='Ato contra Temer em SP é o maior desde o início do julgamento de Dilma https://t.co/tTx3UoKCkL https://t.co/EuJlcpzWOf')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['High above Earth’s tropics, a pattern of winds changed recently in a way not seen in 60+ yrs https://t.co/vsMTvpYnJZ https://t.co/laQBMf42Ls', 'Friends of the Earth founder David Brower said Clinton/Gore did more environmental damage in 4 years than 12 years of Reagan &amp; Bush.', 'Here is a photo of Laurie Hernandez throwing out the first pitch at the Mets game on planet earth https://t.co/zy4K7CHTD1', \"Future climate change field test doesn't make Earth greener: LOS ANGELES (AP) — In the course of a 17-year ex... https://t.co/9FhB6F6OVh\", '【DQX】ちょっくらチョイと朝ドラ。', \"Future climate change field test doesn't make Earth greener: LOS ANGELES (AP) — In the course of a 17-year ex... https://t.co/a2dxrlSlhM\", 'THE QUEEN OF EVERYTHING ON EARTH IS HERE YALLL BETTER GIVE HER THE LOVE SHE DESERVES https://t.co/BCQYgKL02i', 'RT @BitiTendai: Never put any faith infailed predatory regimesThey never change and are not capable of reformSo you come down to earth very…', 'RT @bikinatroll: Flat Earth unable to answer circumnavigation question with any credibility. Or any other question. #FlatEarth https://t.co…', 'A paradise on earth\\n#iraq #the_earth\\n✌ 💪  👇 🇮🇶 https://t.co/IGYgAG3k3G', 'RT @ILoveeBeyonce4: Earth has more than 4 billion years and you are here at the same time as Beyonce. Say thanks for that #BeyDay https://t…', \"#DryCleaning can be #ecofriendly - read how we clean clothing in a way that's both fabric and earth friendly. https://t.co/Te8vtFJNgP\", \"RT @SevillaAnaPat: DAMN HOT AND BEAUTIFUL COUPLE LIVING ON EARTH!!!\\n\\nStunning as always! I'm drooling OTP! #TIMYTheDugdugMoment https://t.c…\", 'RT @KingDouyeAlfred: 2-Let me tell you a story\\n\\nIn the 1543, Copernicus said that the sun was the center of our universe with earth circlin…', 'RT @earth: Pacific Northwest 🌲 https://t.co/0MvCq2vFSS']\n"
     ]
    }
   ],
   "source": [
    "search = api.GetSearch(twitter_query)\n",
    "print([s.text for s in search])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using our customized function that retrieves 5 x 100 tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Status' object has no attribute 'GetId'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-ff3359529fb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweets_txt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtweets_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msearch_for_term\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtwitter_query\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Word count: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Repertoire: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Lexical diversity: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlexical_diversity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-e4800d2ca910>\u001b[0m in \u001b[0;36msearch_for_term\u001b[0;34m(termo, pages, results)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0msearch_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mlist_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mlist_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetId\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mid_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlast\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGetId\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Status' object has no attribute 'GetId'"
     ]
    }
   ],
   "source": [
    "tweets, tweets_txt, tweets_words, names = search_for_term(twitter_query,5,10)\n",
    "    \n",
    "print('Word count: {}'.format(len(tweets_words)))\n",
    "print('Repertoire: {}'.format(len(set(tweets_words))))\n",
    "print('Lexical diversity: {}'.format(lexical_diversity(tweets_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_dist = nltk.FreqDist(tweets_words)\n",
    "freq_dist.plot(40)\n",
    "freq_dist.plot(40, cumulative = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('10 most frequent words')\n",
    "print(freq_dist.keys()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('10 less frequent words')\n",
    "print(freq_dist.keys()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Sorted list of words')\n",
    "print(sorted(set(tweets_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same as before, without stopwords. See variable \"ignorewords\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_tweets_words = [word for word in tweets_words if word not in ignorewords]\n",
    "    \n",
    "freq_new = nltk.FreqDist(new_tweets_words)    \n",
    "freq_new.plot(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_new.plot(50, cumulative = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('10 most frequent words')\n",
    "print(freq_new.keys()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('10 less frequent words')\n",
    "print(freq_new.keys()[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Sorted list of words')\n",
    "print(sorted(set(new_tweets_words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Counting specific words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(new_tweets_words.count(u'prova'))\n",
    "print(freq_new[u'gabarito']) #same as before\n",
    "print(freq_new.freq(u'cola')) #relative to the others"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminating small words or words with specific sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigger_tweets_words = [word for word in new_tweets_words if len(word) > 2]\n",
    "#mediumsized_tweets_words = [word for word in new_tweets_words if len(word) > 2 and len(word) < 9]\n",
    "freq_bigger = nltk.FreqDist(bigger_tweets_words)    \n",
    "freq_bigger.plot(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Citation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "citacoes = [word for word in tweets_words if '@' in word]\n",
    "#citacoes = [word for word in tweets_words if word.startswith('@')]\n",
    "freq_citacoes = nltk.FreqDist(citacoes)\n",
    "freq_citacoes.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_citacoes.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hashtag Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hashtags = [word for word in tweets_words if word.startswith('#')]\n",
    "freq_hashtags = nltk.FreqDist(hashtags)\n",
    "freq_hashtags.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_hashtags.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of Frequent words  \n",
    "Can be used with any of the previous lists'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frequent_words = [word.lower() for word in new_tweets_words if tweets_words.count(word) > 5]\n",
    "freq_dist2 = nltk.FreqDist(frequent_words)\n",
    "freq_dist2.plot(40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Words Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_size_words = nltk.FreqDist([len(w) for w in new_tweets_words])\n",
    "freq_size_words.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_size_words.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bigramas_tweets = nltk.bigrams(new_tweets_words)\n",
    "freqbig = nltk.FreqDist(bigramas_tweets)\n",
    "freqbig.plot(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Names (capitalized words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "freq_names = nltk.FreqDist(names)\n",
    "freq_names.plot(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "badwords =   ['abandoned','abused','accused','addicted','afraid','aggravated',\n",
    "              'aggressive','alone','angry','anguish','annoyed','anxious','apprehensive',\n",
    "              'argumentative','artificial','ashamed','assaulted','at a loss','at risk',\n",
    "              'atrocious','attacked','avoided','awful','awkward','bad','badgered','baffled',\n",
    "              'banned','barren','beat','beaten down','belittled','berated','betrayed',\n",
    "              'bitched at','bitter','bizzare','blacklisted','blackmailed','blamed','bleak',\n",
    "              'blown away','blur','bored','boring','bossed-around','bothered','bothersome',\n",
    "              'bounded','boxed-in','broken','bruised','brushed-off','bugged','bullied',\n",
    "              'bummed','bummed out','burdened','burdensome','burned','burned-out',\n",
    "              'caged in','careless','chaotic','chased','cheated','cheated on','chicken',\n",
    "              'claustrophobic','clingy','closed','clueless','clumsy','coaxed',\n",
    "              'codependent','coerced','cold','cold-hearted','combative','commanded',\n",
    "              'compared','competitive','compulsive','conceited','concerned',\n",
    "              'condescended to','confined','conflicted','confronted','confused',\n",
    "              'conned','consumed','contemplative','contempt','contentious','controlled',\n",
    "              'convicted','cornered','corralled','cowardly','crabby','cramped','cranky',\n",
    "              'crap','crappy','crazy','creeped out','creepy','critical','criticized',\n",
    "              'cross','crowded','cruddy','crummy','crushed','cut-down','cut-off','cynical',\n",
    "              'damaged','damned','dangerous','dark','dazed','dead','deceived','deep',\n",
    "              'defamed','defeated','defective','defenseless','defensive','defiant',\n",
    "              'deficient','deflated','degraded','dehumanized','dejected','delicate',\n",
    "              'deluded','demanding','demeaned','demented','demoralized','demotivated',\n",
    "              'dependent','depleted','depraved','depressed','deprived','deserted',\n",
    "              'deserving of pain/punishment','desolate','despair','despairing',\n",
    "              'desperate','despicable','despised','destroyed','destructive',\n",
    "              'detached','detest','detestable','detested','devalued','devastated',\n",
    "              'deviant','devoid','diagnosed','dictated to','different','difficult',\n",
    "              'directionless','dirty','disabled','disagreeable','disappointed',\n",
    "              'disappointing','disapproved of','disbelieved','discardable','discarded',\n",
    "              'disconnected','discontent','discouraged','discriminated','disdain',\n",
    "              'disdainful','disempowered','disenchanted','disgraced','disgruntled',\n",
    "              'disgust','disgusted','disheartened','dishonest','dishonorable',\n",
    "              'disillusioned','dislike','disliked','dismal','dismayed','disorganized',\n",
    "              'disoriented','disowned','displeased','disposable','disregarded',\n",
    "              'disrespected','dissatisfied','distant','distracted','distraught',\n",
    "              'distressed','disturbed','dizzy','dominated','doomed','double-crossed',\n",
    "              'doubted','doubtful','down','down and out','down in the dumps',\n",
    "              'downhearted','downtrodden','drained','dramatic','dread','dreadful',\n",
    "              'dreary','dropped','drunk','dry','dumb','dumped','dumped on','duped',\n",
    "              'edgy','egocentric','egotistic','egotistical','elusive','emancipated',\n",
    "              'emasculated','embarrassed','emotional','emotionless','emotionally bankrupt',\n",
    "              'empty','encumbered','endangered','enraged','enslaved','entangled','evaded',\n",
    "              'evasive','evicted','excessive','excluded','exhausted','exploited','exposed',\n",
    "              'fail','failful','fake','false','fear','fearful','fed up','flawed','forced',\n",
    "              'forgetful','forgettable','forgotten','fragile','freaked out','frightened',\n",
    "              'frigid','frustrated','furious','gloomy','glum','gothic','grey','grief','grim',\n",
    "              'gross','grossed-out','grotesque','grouchy','grounded','grumpy','guilt-tripped',\n",
    "              'guilty','harassed','hard','hard-hearted','harmed','hassled','hate','hateful',\n",
    "              'hatred','haunted','heartbroken','heartless','heavy-hearted','helpless',\n",
    "              'hesitant','hideous','hindered','hopeless','horrible','horrified','horror',\n",
    "              'hostile','hot-tempered','humiliated','hung up','hung over','hurried','hurt',\n",
    "              'hysterical','idiot','idiotic','ignorant','ignored','ill','ill-tempered',\n",
    "              'imbalanced','imposed-upon','impotent','imprisoned','impulsive','in the dumps',\n",
    "              'in the way','inactive','inadequate','incapable','incommunicative','incompetent',\n",
    "              'incompatible','incomplete','incorrect','indecisive','indifferent',\n",
    "              'indoctrinated','inebriated','ineffective','inefficient','inferior',\n",
    "              'infuriated','inhibited','inhumane','injured','injusticed','insane',\n",
    "              'insecure','insignificant','insincere','insufficient','insulted',\n",
    "              'intense','interrogated','interrupted','intimidated','intoxicated',\n",
    "              'invalidated','invisible','irrational','irritable','irritated',\n",
    "              'isolated','jaded','jealous','jerked around','joyless','judged',\n",
    "              'kept apart','kept away','kept in','kept out','kept quiet','labeled',\n",
    "              'laughable','laughed at','lazy','leaned on','lectured to','left out',\n",
    "              'let down','lied about','lied to','limited','little','lonely','lonesome',\n",
    "              'longing','lost','lousy','loveless','low','mad','made fun of','man handled',\n",
    "              'manipulated','masochistic','messed with','messed up','messy','miffed',\n",
    "              'miserable','misled','mistaken','mistreated','mistrusted','misunderstood',\n",
    "              'mixed-up','mocked','molested','moody','nagged','needy','negative',\n",
    "              'nervous','neurotic','nonconforming','numb','nuts','nutty','objectified',\n",
    "              'obligated','obsessed','obsessive','obstructed','odd','offended',\n",
    "              'on display','opposed','oppressed','out of place','out of touch',\n",
    "              'over-controlled','over-protected','overwhelmed','pain','panic','paranoid',\n",
    "              'passive','pathetic','pessimistic','petrified','phony','picked on','pissed',\n",
    "              'pissed off','plain','played with','pooped','poor','powerless','pre-judged',\n",
    "              'preached to','preoccupied','predjudiced','pressured','prosecuted',\n",
    "              'provoked','psychopathic','psychotic','pulled apart','pulled back',\n",
    "              'punished','pushed','pushed away','put down','puzzled','quarrelsome',\n",
    "              'queer','questioned','quiet','rage','raped','rattled','regret','rejected',\n",
    "              'resented','resentful','responsible','retarded','revengeful','ridiculed',\n",
    "              'ridiculous','robbed','rotten','sad','sadistic','sarcastic','scared',\n",
    "              'scarred','screwed','screwed over','screwed up','self-centered','self-conscious',\n",
    "              'self-destructive','self-hatred','selfish','sensitive','shouted at','shy',\n",
    "              'singled-out','slow','small','smothered','snapped at','spiteful','stereotyped',\n",
    "              'strange','stressed','stretched','stuck','stupid','submissive','suffering',\n",
    "              'suffocated','suicidal','superficial','suppressed','suspicious','worse','worst'\n",
    "              ,'bankrupcy','jobs','shit','socialism','#sob']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "goodwords =  ['Abundant','Accomplished','Achieving','Active','Admirable','Adorable',\n",
    "              'Adventurous','Admired','Affluent','Agreeable','Alert','Aligned','Alive',\n",
    "              'Amazing','Appealing','Appreciate','Artistic','Astounding','Astute',\n",
    "              'Attentive','Attractive','Auspicious','Authentic','Awake','Aware','Awesome',\n",
    "              'Beaming','Beautiful','Better','Best','Blessed','Bliss','Bold','Bright','Brilliant',\n",
    "              'Brisk','Buoyant','Calm','Capable','Centered','Certain','Charming',\n",
    "              'Cheerful','Clear','Clever','Competent','Complete','Confident','Connected',\n",
    "              'Conscious','Considerate','Convenient','Courageous','Creative','Daring',\n",
    "              'Dazzling','Delicious','Delightful','Desirable','Determined','Diligent',\n",
    "              'Discerning','Discover','Dynamic','Eager','Easy','Efficient','Effortless',\n",
    "              'Elegant','Eloquent','Energetic','Endless','Enhancing','Engaging','Enormous'\n",
    "              ,'Enterprising','Enthusiastic','Enticing','Excellent','Exceptional','Exciting'\n",
    "              ,'Experienced','Exquisite','Fabulous','Fair','Far-Sighted','Fascinating',\n",
    "              'Fine','Flattering','Flourishing','Fortunate','Free','Friendly','Fulfilled',\n",
    "              'Fun','Generous','Genuine','Gifted','Glorious','Glowing','Good','Good-Looking',\n",
    "              'Gorgeous','Graceful','Gracious','Grand','Great','Handsome','Happy','Hardy',\n",
    "              'Harmonious','Healed','Healthy','Helpful','Honest','Humorous','Ideal',\n",
    "              'Imaginative','Impressive','Industrious','Ingenious','Innovative','Inspired',\n",
    "              'Intelligent','Interested','Interesting','Intuitive','Inventive','Invincible',\n",
    "              'Inviting','Irresistible','Joyous','Judicious','Keen','Kind','Knowing','Leader',\n",
    "              'Limitless','Lively','Loving','Lucky','Luminous','Magical','Magnificent',\n",
    "              'Marvellous','Masterful','Mighty','Miraculous','Motivated','Natural','Neat',\n",
    "              'Nice','Nurturing','Noble','Optimistic','Outstanding','Passionate','Peaceful',\n",
    "              'Perfect','Persevering','Persistent','Playful','Pleasing','Plentiful','Positive',\n",
    "              'Powerful','Precious','Prepared','Productive','Profound','Prompt','Prosperous',\n",
    "              'Proud','Qualified','Quick','Radiant','Reasonable','Refined','Refreshing',\n",
    "              'Relaxing','Reliable','Remarkable','Resolute','Resourceful','Respected',\n",
    "              'Rewarding','Robust','Safe','Satisfied','Secure','Seductive','Self-Reliant',\n",
    "              'Sensational','Sensible','Sensitive','Serene','Sharing','Skilful','Smart',\n",
    "              'Smashing','Smooth','Sparkling','Spiritual','Splendid','Strong','Stunning',\n",
    "              'Successful','Superb','Swift','Talented','Tenacious','Terrific','Thankful',\n",
    "              'Thrilling','Thriving','Timely','Trusting','Truthful','Ultimate','Unique',\n",
    "              'Valiant','Valuable','Versatile','Vibrant','Victorious','Vigorous','Vivacious',\n",
    "              'Vivid','Warm','Wealthy','Well','Whole','Wise','Wonderful','Worthy','Young',\n",
    "              'Youthful','Zeal','Zest']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def percentage(count, total):\n",
    "    return 100 * count / float(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sentiment_analysis(texto, goodwords, badwords):\n",
    "    '''\n",
    "    Not a sophisticated one, but the main idea is present.\n",
    "    Please read: http://alias-i.com/lingpipe/demos/tutorial/sentiment/read-me.html\n",
    "    '''\n",
    "    goodness = 0\n",
    "    badness = 0    \n",
    "    for word in goodwords:\n",
    "        goodness += percentage(texto.count(word.lower()), len(texto))\n",
    "    for word in badwords:\n",
    "        badness += percentage(texto.count(word.lower()), len(texto))\n",
    "    if badness:\n",
    "        ratio = goodness/float(badness)\n",
    "    print(u'Grau de negatividade: {}'.format(badness))\n",
    "    print(u'Grau de positividade: {}'.format(goodness))\n",
    "    if badness:\n",
    "        print(u'Razão: {}'.format(ratio))\n",
    "    return goodness, badness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentiment_analysis(tweets_words, goodwords, badwords);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Geographic Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pypi.python.org/pypi/basemap/1.0.7  \n",
    "http://matplotlib.org/basemap/  \n",
    "http://matplotlib.org/basemap/users/installing.html  \n",
    "http://nbviewer.ipython.org/github/ehmatthes/intro_programming/blob/master/notebooks/visualization_earthquakes.ipynb  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#http://matplotlib.org/basemap/api/basemap_api.html\n",
    "from mpl_toolkits.basemap import Basemap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "msgpublicas = api.GetStreamSample()\n",
    "geo_points = 0\n",
    "lats, lons = [], []\n",
    "users = []\n",
    "while geo_points < 20:\n",
    "    tweet = msgpublicas.next()\n",
    "    if tweet.has_key('coordinates') and tweet['coordinates'] != None:\n",
    "        coords = tweet['coordinates']['coordinates']\n",
    "        user = tweet['user']['id']\n",
    "        print(u'Usuário {} nas coordenadas {}'.format(user, [coords[1],coords[0]]))\n",
    "        lons.append(float(coords[0]))\n",
    "        lats.append(float(coords[1]))\n",
    "        users.append(user)\n",
    "        geo_points +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map = Basemap(projection='robin', resolution = 'l', area_thresh = 1000.0, lat_0=0, lon_0=0)\n",
    "\n",
    "map.drawcoastlines()\n",
    "map.drawcountries()\n",
    "map.fillcontinents(color = '#FFFFCC') #http://www.w3schools.com/tags/ref_colorpicker.asp\n",
    "map.drawmapboundary()\n",
    "map.drawmeridians(np.arange(0, 360, 30))\n",
    "map.drawparallels(np.arange(-90, 90, 30))\n",
    "\n",
    "x,y = map(lons, lats)\n",
    "map.plot(x, y, 'ro', markersize=6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "map = Basemap(projection='merc', lat_0 = -22, lon_0 = -56.5,resolution = 'h', area_thresh = 0.1, \n",
    "              llcrnrlon=-83.0, llcrnrlat=-57.0, urcrnrlon=-30.0, urcrnrlat=13.0)\n",
    " \n",
    "map.drawcoastlines()\n",
    "map.drawcountries()\n",
    "map.fillcontinents(color = 'coral')\n",
    "map.drawmapboundary()\n",
    "\n",
    "x,y = map(lons, lats)\n",
    "map.plot(x, y, 'bo', markersize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zoom em uma coordenada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def gmap(lat,lon,zoom=10):\n",
    "    # Google Maps URL template for an iframe\n",
    "    google_maps_url = \"http://maps.google.com/maps?q={0}+{1}&ie=UTF8&t=h&z={2}&{0},{1}&output=embed\".format(lat,lon,zoom)\n",
    "    display(IFrame(google_maps_url, '800px', '600px'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gmap(lats[0],lons[0],4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graphs\n",
    "\n",
    "http://networkx.lanl.gov/  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_rt_origins(tweet):\n",
    "    ''' Regex adapted from \n",
    "    http://stackoverflow.com/questions/655903/python-regular-expression-for-retweets'''\n",
    "    rt_patterns = re.compile(r\"(RT|via)((?:\\b\\W*@\\w+)+)\", re.IGNORECASE)\n",
    "    rt_origins = []\n",
    "    try:\n",
    "        rt_origins += [mention.strip() for mention in rt_patterns.findall(tweet)[0][1].split()]\n",
    "    except IndexError, e:\n",
    "        pass\n",
    "    return [rto.strip(\"@\") for rto in rt_origins]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_graph_retweets(tweets):\n",
    "    g = nx.DiGraph()\n",
    "    for tweet in tweets:\n",
    "        rt_origins = get_rt_origins(tweet.text)\n",
    "        if not rt_origins:\n",
    "            continue\n",
    "        for rt_origin in rt_origins:\n",
    "            g.add_edge(rt_origin, tweet.user.screen_name, {'tweet_id': tweet.id})\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "g_rt = create_graph_retweets(tweets)\n",
    "print(\"Number of nodes is: {}\\n\".format(g_rt.number_of_nodes()))\n",
    "print(\"Number of edges is: {}\\n\".format(g_rt.number_of_edges()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import operator\n",
    "sorted_dic = sorted(g_rt.degree().items(), key=operator.itemgetter(1), reverse=True)\n",
    "sorted_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dic = nx.degree(g_rt)\n",
    "plt.plot(sorted(dic.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_dotfile(g):\n",
    "    try:\n",
    "        nx.drawing.write_dot(g, pathdotfile)\n",
    "        print >> sys.stderr, 'Graph exported for file: {}'.format(pathdotfile)\n",
    "    except (ImportError, UnicodeEncodeError): \n",
    "        # Este bloco serve para usuarios de windows, que certamente terao problemas\n",
    "        # com o metodo nx.drawing.write_dot. Tambem serve para os casos em que temos\n",
    "        # problemas com o unicode\n",
    "        dot = [u'\"{}\" -> \"{}\" [tweet_id={}]'.format(n1, n2, g[n1][n2]['tweet_id']) for (n1, n2) in g.edges()]\n",
    "        f = codecs.open(pathdotfile, 'w', encoding='utf-8')\n",
    "        f.write('''strict digraph {{}}'''.format(';\\n'.join(dot), ))\n",
    "        f.close()\n",
    "        print >> sys.stderr, 'Graph exported for file: {}'.format(pathdotfile)\n",
    "        return f.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_dotfile(g_rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving a dotfile\n",
    "\n",
    "Obs: To generate a png graph from the dotfile, type in the Unix Prompt: \n",
    "'circo -Tpng -Gcharset=latin1 -Ograph_retweet graph_retweet.dot'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Chamando um programa externo ao Ipython com o operador !\n",
    "!dot -Tpng /home/rsouza/Dropbox/Renato/ModMinDados/outputs/graph_retweet.dot -o /home/rsouza/Dropbox/Renato/ModMinDados/outputs/graph_retweet.png\n",
    "Image(pathpngfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nx.draw_networkx_labels(g_rt,pos=nx.spring_layout(g_rt),font_size=9)\n",
    "nx.draw(g_rt)\n",
    "#nx.draw_random(g_rt)\n",
    "#nx.draw_circular(g_rt)\n",
    "#nx.draw_spectral(g_rt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving a HTML file that uses javascript for visualizing the graph (needs a template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_protovis_file(g):\n",
    "    '''A visualization alternative is \"protovis\" javascript\n",
    "    It uses the files \"template_protoviz.html and \"protovis-r3.2.js\"\n",
    "    '''\n",
    "    nodes = g.nodes()\n",
    "    indexed_nodes = {}\n",
    "    idx = 0\n",
    "    for n in nodes:\n",
    "        indexed_nodes.update([(n, idx,)])\n",
    "        idx += 1\n",
    "    links = []\n",
    "    for n1, n2 in g.edges():\n",
    "        links.append({'source': indexed_nodes[n2],'target': indexed_nodes[n1]})\n",
    "    json_data = json.dumps({\"nodes\" : [{\"nodeName\" : n} for n in nodes], \"links\" : links}, indent=4)\n",
    "    html = open(pathtemplate).read().format(json_data,)\n",
    "    f = open(pathprotofile, 'w')\n",
    "    f.write(html)\n",
    "    f.close()\n",
    "    print >> sys.stderr, 'Graph exported for file: {}'.format(pathprotofile)\n",
    "    return f.name, html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "s = save_protovis_file(g_rt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#!chromium /home/rsouza/Dropbox/Renato/ModMinDados/outputs/graph_retweet.html\n",
    "# http://docs.python.org/library/webbrowser.html \n",
    "webbrowser.open(os.path.join('file://', pathprotofile))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
